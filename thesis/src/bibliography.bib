@article{lamport2019time,
  author = {Lamport, Leslie},
  title = {Time, clocks, and the ordering of events in a distributed system},
  year = {1978},
  issue_date = {July 1978},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {21},
  number = {7},
  issn = {0001-0782},
  url = {https://doi.org/10.1145/359545.359563},
  doi = {10.1145/359545.359563},
  abstract = {The concept of one event happening before another in a distributed system is examined, and is shown to define a partial ordering of the events. A distributed algorithm is given for synchronizing a system of logical clocks which can be used to totally order the events. The use of the total ordering is illustrated with a method for solving synchronization problems. The algorithm is then specialized for synchronizing physical clocks, and a bound is derived on how far out of synchrony the clocks   can become.},
  journal = {Commun. ACM},
  month = jul,
  pages = {558–565},
  numpages = {8},
  keywords = {clock synchronization, computer networks, distributed systems, multiprocess systems}
}
@article{gomes2017verifying,
  author = {Gomes, Victor B. F. and Kleppmann, Martin and Mulligan, Dominic P. and Beresford, Alastair R.},
  title = {Verifying strong eventual consistency in distributed systems},
  year = {2017},
  issue_date = {October 2017},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {1},
  number = {OOPSLA},
  url = {https://doi.org/10.1145/3133933},
  doi = {10.1145/3133933},
  abstract = {Data replication is used in distributed systems to maintain up-to-date copies of shared data across multiple computers in a network. However, despite decades of research, algorithms for achieving consistency in replicated systems are still poorly understood. Indeed, many published algorithms have later been shown to be incorrect, even some that were accompanied by supposed mechanised proofs of correctness. In this work, we focus on the correctness of Conflict-free Replicated Data Types (CRDTs),   a class of algorithm that provides strong eventual consistency guarantees for replicated data. We develop a modular and reusable framework in the Isabelle/HOL interactive proof assistant for verifying the correctness of CRDT algorithms. We avoid correctness issues that have dogged previous mechanised proofs in this area by including a network model in our formalisation, and proving that our theorems hold in all possible network behaviours. Our axiomatic network model is a standard abstraction that   accurately reflects the behaviour of real-world computer networks. Moreover, we identify an abstract convergence theorem, a property of order relations, which provides a formal definition of strong eventual consistency. We then obtain the first machine-checked correctness theorems for three concrete CRDTs: the Replicated Growable Array, the Observed-Remove Set, and an Increment-Decrement Counter. We find that our framework is highly reusable, developing proofs of correctness for the latter two CRDTs in a   few hours and with relatively little CRDT-specific code.},
  journal = {Proc. ACM Program. Lang.},
  month = oct,
  articleno = {109},
  numpages = {28},
  keywords = {verification, strong eventual consistency, replication, distributed systems, convergence, automated theorem proving, CRDTs}
}
@TechReport{kleppmann2022assessing,
  author = {Kleppmann, Martin},
  title =  {{Assessing the understandability of a distributed algorithm by tweeting buggy pseudocode}},
  year =  2022,
  month =  may,
  url =  {https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-969.pdf},
  institution = {University of Cambridge, Computer Laboratory},
  doi = {10.48456/tr-969},
  number = {UCAM-CL-TR-969}
}
@techreport{shapiro2011comprehensive,
  title = {{A comprehensive study of Convergent and Commutative Replicated Data Types}},
  AUTHOR = {Shapiro, Marc and Pregui{\c c}a, Nuno and Baquero, Carlos and Zawirski, Marek},
  URL = {https://inria.hal.science/inria-00555588},
  TYPE = {Research Report},
  NUMBER = {RR-7506},
  PAGES = {50},
  INSTITUTION = {{Inria -- Centre Paris-Rocquencourt ; INRIA}},
  YEAR = {2011},
  MONTH = Jan,
  KEYWORDS = {eventual consistency ; optimistic replication ; replicated data types ; distributed algorithms ; distributed systems ; Data replication ; commutative operations},
  PDF = {https://inria.hal.science/inria-00555588v1/file/techreport.pdf},
  HAL_ID = {inria-00555588},
  HAL_VERSION = {v1},
}
@article{baquero2017pure,
  author       = {Carlos Baquero and Paulo S{\'{e}}rgio Almeida and Ali Shoker},
  title        = {Pure Operation-Based Replicated Data Types},
  journal      = {CoRR},
  volume       = {abs/1710.04469},
  year         = {2017},
  url          = {http://arxiv.org/abs/1710.04469},
  eprinttype    = {arXiv},
  eprint       = {1710.04469},
  timestamp    = {Tue, 17 Sep 2019 14:15:20 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1710-04469.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@manual{nom,
  author = {{The Nom Contributors}},
  title  = {{Nom Parser Combinator Framework}},
  year   = {2025},
  note   = {\url{https://github.com/rust-bakery/nom}}
}
@manual{automerge,
  author = {{The Automerge Contributors}},
  title  = {{Automerge CRDT Library}},
  year   = {2024},
  note   = {\url{https://github.com/automerge}}
}
@manual{yjs,
  author = {{The Yjs Contributors}},
  title  = {{Yjs CRDT Library}},
  year   = {2025},
  note   = {\url{https://github.com/yjs/yjs}}
}
@manual{collabs,
  author = {{The Collabs Contributors}},
  title  = {{Collabs CRDT Library}},
  year   = {2025},
  note   = {\url{https://github.com/composablesys/collabs}}
}
@manual{loro,
  author = {{The Loro Contributors}},
  title  = {{Loro CRDT Library}},
  year   = {2025},
  note   = {\url{https://github.com/loro-dev/loro}}
}
@manual{livestore,
  author = {{The LiveStore Contributors}},
  title  = {{LiveStore Library}},
  year   = {2025},
  note   = {\url{https://github.com/livestorejs/livestore}}
}
@manual{pgivm,
  author = {{The pg\_ivm Contributors}},
  title  = {{pg\_ivm PostgreSQL Extension}},
  year   = {2025},
  note   = {\url{https://github.com/sraoss/pg_ivm}}
}
@manual{felderarepo,
  author = {{The Feldera Contributors}},
  title  = {{Feldera and DBSP Library}},
  year   = {2025},
  note   = {\url{https://github.com/feldera/feldera}}
}
@online{felderainc,
  author = {{Feldera, Inc.}},
  title = {{Feldera's} Homepage},
  year = 2025,
  url = {https://web.archive.org/web/20250714140906/https://www.feldera.com/},
  urldate = {2025-07-14}
}
@manual{datafrog,
  author = {{The Datafrog Contributors}},
  title  = {Datafrog},
  year   = {2025},
  note   = {\url{https://github.com/rust-lang/datafrog}}
}
@manual{ddlog,
  author = {{The Differential Datalog Contributors}},
  title  = {Differential Datalog},
  year   = {2025},
  note   = {\url{https://github.com/vmware-archive/differential-datalog}}
}
@inproceedings{ddlogpaper,
   author = {Leonid Ryzhyk and Mihai Budiu},
   title = {Differential Datalog},
   booktitle = {Datalog 2.0},
   address = {Philadelphia, PA},
   month = {June 4-5},
   year = {2019},
   abstract = {Many real-world applications based on deductive databases require
                 incrementally updating output relations (tables) in response to changes
                 to input relations. To make such applications easier to implement we
                 have created Differential Datalog (DDlog), a dialect of Datalog that
                 automates incremental computation. A DDlog programmer writes
                 traditional, non-incremental Datalog programs. The execution model of
                 DDlog is however fully incremental: at runtime DDlog programs receive
                 streams of changes to the input relations (insertions or deletions) and
                 produce streams of corresponding changes to derived relations. The
                 DDlog compiler translates DDlog programs to Differential Dataflow (DD)
                 programs; DD provides an incremental execution engine supporting all
                 the relational operators, including fixed-point. The DDlog runtime
                 automatically maintains the indexes required to efficiently compute
                 output updates. \par The DDlog language is targeted for system
                 builders. In consequence, the language emphasizes usability, by
                 providing a rich type system, a powerful expression language, a module
                 system, including string manipulation, arithmetic, and integration with
                 C, Rust, and Java. The code is open-source, available using an MIT
                 permissive license.},
   url = {https://mihaibudiu.github.io/work/ddlog.pdf},
   confweb = {https://sites.sju.edu/plw/datalog2/}
}
@inproceedings{kleppmann2019local,
  author = {Kleppmann, Martin and Wiggins, Adam and van Hardenberg, Peter and McGranaghan, Mark},
  title = {Local-first software: you own your data, in spite of the cloud},
  year = {2019},
  isbn = {9781450369954},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3359591.3359737},
  doi = {10.1145/3359591.3359737},
  abstract = {Cloud apps like Google Docs and Trello are popular because they enable real-time collaboration with colleagues, and they make it easy for us to access our work from all of our devices. However, by centralizing data storage on servers, cloud apps also take away ownership and agency from users. If a service shuts down, the software stops functioning, and data created with that software is lost. In this article we propose local-first software, a set of principles for software that enables both   collaboration and ownership for users. Local-first ideals include the ability to work offline and collaborate across multiple devices, while also improving the security, privacy, long-term preservation, and user control of data. We survey existing approaches to data storage and sharing, ranging from email attachments to web apps to Firebase-backed mobile apps, and we examine the trade-offs of each. We look at Conflict-free Replicated Data Types (CRDTs): data structures that are multi-user from the ground   up while also being fundamentally local and private. CRDTs have the potential to be a foundational technology for realizing local-first software. We share some of our findings from developing local-first software prototypes at the Ink \& Switch research lab over the course of several years. These experiments test the viability of CRDTs in practice, and explore the user interface challenges for this new data model. Lastly, we suggest some next steps for moving towards local-first software: for researchers,   for app developers, and a startup opportunity for entrepreneurs.},
  booktitle = {Proceedings of the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
  pages = {154–178},
  numpages = {25},
  keywords = {CRDTs, collaboration software, data ownership, mobile computing, peer-to-peer communication},
  location = {Athens, Greece},
  series = {Onward! 2019}
}
@misc{preguicca2018conflict,
  title={Conflict-free Replicated Data Types: An Overview},
  author={Nuno Preguiça},
  year={2018},
  eprint={1806.10254},
  archivePrefix={arXiv},
  primaryClass={cs.DC},
  url={https://arxiv.org/abs/1806.10254},
}
@inproceedings{stewen2024undo,
  author = {Stewen, Leo and Kleppmann, Martin},
  title = {Undo and Redo Support for Replicated Registers},
  year = {2024},
  isbn = {9798400705441},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3642976.3653029},
  doi = {10.1145/3642976.3653029},
  abstract = {Undo and redo functionality is ubiquitous in collaboration software. In single user settings, undo and redo are well understood. However, when multiple users edit a document, concurrency may arise, leading to a non-linear operation history. This renders undo and redo more complex both in terms of their semantics and implementation.We survey the undo and redo semantics of current mainstream collaboration software and derive principles for undo and redo behavior in a collaborative setting. We   then apply these principles to a simple CRDT, the Multi-Valued Replicated Register, and present a novel undo and redo algorithm that implements the undo and redo semantics that we believe are most consistent with users' expectations.},
  booktitle = {Proceedings of the 11th Workshop on Principles and Practice of Consistency for Distributed Data},
  pages = {1–7},
  numpages = {7},
  keywords = {undo, redo, CRDT, eventual consistency, collaborative editing},
  location = {Athens, Greece},
  series = {PaPoC '24}
}
@article{budiu2024dbsp,
  author = {Budiu, Mihai and Chajed, Tej and McSherry, Frank and Ryzhyk, Leonid and Tannen, Val},
  title = {{DBSP}: Incremental Computation on Streams and Its Applications to Databases},
  year = {2024},
  issue_date = {March 2024},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {53},
  number = {1},
  issn = {0163-5808},
  url = {https://doi.org/10.1145/3665252.3665271},
  doi = {10.1145/3665252.3665271},
  abstract = {We describe DBSP, a framework for incremental computation. Incremental computations repeatedly evaluate a function on some input values that are "changing". The goal of an efficient implementation is to "reuse" previously computed results. Ideally, when presented with a new change to the input, an incremental computation should only perform work proportional to the size of the changes of the input, rather than to the size of the entire dataset.},
  journal = {SIGMOD Rec.},
  month = may,
  pages = {87–95},
  numpages = {9}
}
@article{budiu2025dbsp,
  author = {Budiu, Mihai and Ryzhyk, Leonid and Zellweger, Gerd and Pfaff, Ben and Suresh, Lalith and Kassing, Simon and Gyawali, Abhinav and Budiu, Matei and Chajed, Tej and McSherry, Frank and Tannen, Val},
  title = {{DBSP}: automatic incremental view maintenance for rich query languages},
  year = {2025},
  issue_date = {Jul 2025},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  volume = {34},
  number = {4},
  issn = {1066-8888},
  url = {https://doi.org/10.1007/s00778-025-00922-y},
  doi = {10.1007/s00778-025-00922-y},
  abstract = {Incremental view maintenance (IVM) has long been a central problem in database theory and practice. Many solutions have been proposed for restricted classes of database languages (such as the relational algebra or Datalog), restricted classes of queries, and restricted classes of database changes. In this paper we give a general, heuristic-free solution to this problem in 4 steps: (1) we describe a simple but expressive language called DBSP for describing computations over data streams; (2) we   give a new mathematical definition of IVM using DBSP; (3) we give an algorithm for converting any DBSP program into an incremental program; this algorithm reduces the problem of incrementalizing a complex query to the problem of incrementalizing the primitive operations that compose the query. Finally, (4) we show that practical database query languages, such as SQL and Datalog, can be directly implemented on top of DBSP, using primitives that have efficient incremental implementations. As a consequence,   we obtain a general recipe for efficient IVM for essentially arbitrary queries written in all these languages.},
  journal = {The VLDB Journal},
  month = may,
  numpages = {28},
  keywords = {IVM, Incremental computation, Views, Databases, Streams}
}
@inproceedings{mcsherry2013differential,
  author = {McSherry, Frank and Murray, Derek and Isaacs, Rebecca and Isard, Michael},
  title = {Differential dataflow},
  booktitle = {Proceedings of {CIDR} 2013},
  year = {2013},
  month = jan,
  abstract = {Existing computational models for processing continuously changing input data are unable to efficiently support iterative queries except in limited special cases. This makes it difficult to perform complex tasks, such as social-graph analysis on changing data at interactive timescales, which would greatly benefit those analyzing the behavior of services like Twitter. In this paper we introduce a new model called differential computation, which extends traditional incremental computation to   allow arbitrarily nested iteration, and explain---with reference to a publicly available prototype system called Naiad---how differential computation can be efficiently implemented in the context of a declarative data-parallel dataflow language. The resulting system makes it easy to program previously intractable algorithms such as incrementally updated strongly connected components, and integrate them with data transformation operations to obtain practically relevant insights from real data streams.},
  url = {https://www.microsoft.com/en-us/research/publication/differential-dataflow/},
  edition = {Proceedings of {CIDR} 2013},
}
@inproceedings{timelydataflow,
  author = {Murray, Derek G. and McSherry, Frank and Isaacs, Rebecca and Isard, Michael and Barham, Paul and Abadi, Mart\'{\i}n},
  title = {Naiad: a timely dataflow system},
  year = {2013},
  isbn = {9781450323888},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/2517349.2522738},
  doi = {10.1145/2517349.2522738},
  abstract = {Naiad is a distributed system for executing data parallel, cyclic dataflow programs. It offers the high throughput of batch processors, the low latency of stream processors, and the ability to perform iterative and incremental computations. Although existing systems offer some of these features, applications that require all three have relied on multiple platforms, at the expense of efficiency, maintainability, and simplicity. Naiad resolves the complexities of combining these features in one   framework.A new computational model, timely dataflow, underlies Naiad and captures opportunities for parallelism across a wide class of algorithms. This model enriches dataflow computation with timestamps that represent logical points in the computation and provide the basis for an efficient, lightweight coordination mechanism.We show that many powerful high-level programming models can be built on Naiad's low-level primitives, enabling such diverse tasks as streaming data analysis, iterative machine   learning, and interactive graph mining. Naiad outperforms specialized systems in their target application domains, and its unique features enable the development of new high-performance applications.},
  booktitle = {Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles},
  pages = {439–455},
  numpages = {17},
  location = {Farminton, Pennsylvania},
  series = {SOSP '13}
}
@online{materializeinc,
  author = {{Materialize, Inc.}},
  title = {{Materialize's} Homepage},
  year = 2025,
  url = {https://web.archive.org/web/20250714140957/https://materialize.com/},
  urldate = {2025-07-14}
}
@article{abo2024convergence,
  author = {Abo Khamis, Mahmoud and Ngo, Hung Q. and Pichler, Reinhard and Suciu, Dan and Wang, Yisu Remy},
  title = {Convergence of datalog over (Pre-) Semirings},
  year = {2024},
  issue_date = {April 2024},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {71},
  number = {2},
  issn = {0004-5411},
  url = {https://doi.org/10.1145/3643027},
  doi = {10.1145/3643027},
  abstract = {Recursive queries have been traditionally studied in the framework of datalog, a language that restricts recursion to monotone queries over sets, which is guaranteed to converge in polynomial time in the size of the input. But modern big data systems require recursive computations beyond the Boolean space. In this article, we study the convergence of datalog when it is interpreted over an arbitrary semiring. We consider an ordered semiring, define the semantics of a datalog program as a least   fixpoint in this semiring, and study the number of steps required to reach that fixpoint, if ever. We identify algebraic properties of the semiring that correspond to certain convergence properties of datalog programs. Finally, we describe a class of ordered semirings on which one can use the semi-na\"{\i}ve evaluation algorithm on any datalog program.},
  journal = {J. ACM},
  month = apr,
  articleno = {8},
  numpages = {55},
  keywords = {Datalog, semirings, fixpoint}
}
@article{green2013datalog,
  author = {Green, Todd J. and Huang, Shan Shan and Loo, Boon Thau and Zhou, Wenchao},
  title = {Datalog and Recursive Query Processing},
  year = {2013},
  issue_date = {November 2013},
  publisher = {Now Publishers Inc.},
  address = {Hanover, MA, USA},
  volume = {5},
  number = {2},
  issn = {1931-7883},
  url = {https://doi.org/10.1561/1900000017},
  doi = {10.1561/1900000017},
  abstract = {In recent years, we have witnessed a revival of the use of recursive queries in a variety of emerging application domains such as data integration and exchange, information extraction, networking, and program analysis. A popular language used for expressing these queries is Datalog. This paper surveys for a general audience the Datalog language, recursive query processing, and optimization techniques. This survey differs from prior surveys written in the eighties and nineties in its   comprehensiveness of topics, its coverage of recent developments and applications, and its emphasis on features and techniques beyond "classical" Datalog which are vital for practical applications. Specifically, the topics covered include the core Datalog language and various extensions, semantics, query optimizations, magic-sets optimizations, incremental view maintenance, aggregates, negation, and types. We conclude the paper with a survey of recent systems and applications that use Datalog and recursive   queries.},
  journal = {Foundations and Trends Databases},
  month = nov,
  pages = {105–195},
  numpages = {91}
}
@online{kleppmann2018data,
  title={Data structures as queries: Expressing {CRDTs} using {Datalog}},
  author={Kleppmann, Martin},
  year={2018},
  url={https://martin.kleppmann.com/2018/02/26/dagstuhl-data-consistency.html},
}
@article{laddad2022keep,
  author = {Laddad, Shadaj and Power, Conor and Milano, Mae and Cheung, Alvin and Crooks, Natacha and Hellerstein, Joseph M.},
  title = {Keep {CALM} and {CRDT} On},
  year = {2022},
  issue_date = {December 2022},
  publisher = {VLDB Endowment},
  volume = {16},
  number = {4},
  issn = {2150-8097},
  url = {https://doi.org/10.14778/3574245.3574268},
  doi = {10.14778/3574245.3574268},
  abstract = {Despite decades of research and practical experience, developers have few tools for programming reliable distributed applications without resorting to expensive coordination techniques. Conflict-free replicated datatypes (CRDTs) are a promising line of work that enable coordination-free replication and offer certain eventual consistency guarantees in a relatively simple object-oriented API. Yet CRDT guarantees extend only to data updates; observations of CRDT state are unconstrained and unsafe.   We propose an agenda that embraces the simplicity of CRDTs, but provides richer, more uniform guarantees. We extend CRDTs with a query model that reasons about which queries are safe without coordination by applying monotonicity results from the CALM Theorem, and lay out a larger agenda for developing CRDT data stores that let developers safely and efficiently interact with replicated application state.},
  journal = {Proc. VLDB Endow.},
  month = dec,
  pages = {856–863},
  numpages = {8}
}
@inproceedings{neumann2024critique,
  author       = {Thomas Neumann and Viktor Leis},
  title        = {A Critique of Modern {SQL} and a Proposal Towards a Simple and Expressive Query Language},
  booktitle    = {14th Conference on Innovative Data Systems Research, {CIDR} 2024, Chaminade, HI, USA, January 14-17, 2024},
  publisher    = {www.cidrdb.org},
  year         = {2024},
  url          = {https://www.cidrdb.org/cidr2024/papers/p48-neumann.pdf},
  timestamp    = {Fri, 05 Apr 2024 17:17:09 +0200},
  biburl       = {https://dblp.org/rec/conf/cidr/0001L24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{hirn2023fix,
  author       = {Denis Hirn and Torsten Grust},
  title        = {A Fix for the Fixation on Fixpoints},
  booktitle    = {13th Conference on Innovative Data Systems Research, {CIDR} 2023, Amsterdam, The Netherlands, January 8-11, 2023},
  publisher    = {www.cidrdb.org},
  year         = {2023},
  url          = {https://www.cidrdb.org/cidr2023/papers/p14-hirn.pdf},
  timestamp    = {Wed, 19 Jul 2023 17:21:16 +0200},
  biburl       = {https://dblp.org/rec/conf/cidr/HirnG23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@online{mcsherry2022recursion,
  author = {McSherry, Frank},
  title = {{Recursion in Materialize}},
  year = 2022,
  url = {https://web.archive.org/web/20241126143413/https://github.com/frankmcsherry/blog/blob/master/posts/2022-12-25.md},
  urldate = {2024-11-26}
}
@online{sampson2023flattening,
  author = {Sampson, Adrian},
  title = {{Flattening ASTs (and Other Compiler Data Structures)}},
  year = 2023,
  url = {https://web.archive.org/web/20250613165634/https://www.cs.cornell.edu/~asampson/blog/flattening.html},
  urldate = {2025-07-03}
}
@article{khamis2022datalog,
  author = {Khamis, Mahmoud Abo and Ngo, Hung Q. and Pichler, Reinhard and Suciu, Dan and Remy Wang, Yisu},
  title = {Datalog in Wonderland},
  year = {2022},
  issue_date = {June 2022},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {51},
  number = {2},
  issn = {0163-5808},
  url = {https://doi.org/10.1145/3552490.3552492},
  doi = {10.1145/3552490.3552492},
  abstract = {Modern data analytics applications, such as knowledge graph reasoning and machine learning, typically involve recursion through aggregation. Such computations pose great challenges to both system builders and theoreticians: first, to derive simple yet powerful abstractions for these computations; second, to define and study the semantics for the abstractions; third, to devise optimization techniques for these computations.In recent work we presented a generalization of Datalog called Datalog,   which addresses these challenges. Datalog is a simple abstraction, which allows aggregates to be interleaved with recursion, and retains much of the simplicity and elegance of Datalog. We define its formal semantics based on an algebraic structure called Partially Ordered Pre-Semirings, and illustrate through several examples how Datalog can be used for a variety of applications. Finally, we describe a new optimization rule for Datalog, called the FGH-rule, then illustrate the FGH-rule on several examples,   including a simple magic-set rewriting, generalized semi-na\"{\i}ve evaluation, and a bill-of-material example, and briefly discuss the implementation of the FGH-rule and present some experimental validation of its effectiveness.},
  journal = {SIGMOD Rec.},
  month = jul,
  pages = {6–17},
  numpages = {12}
}
@article{sanjuan2020merkle,
  author       = {Hector Sanjuan and Samuli Poyhtari and Pedro Teixeira and Ioannis Psaras},
  title        = {{Merkle-CRDTs: Merkle-DAGs meet CRDTs}},
  journal      = {CoRR},
  volume       = {abs/2004.00107},
  year         = {2020},
  url          = {https://arxiv.org/abs/2004.00107},
  eprinttype    = {arXiv},
  eprint       = {2004.00107},
  timestamp    = {Wed, 08 Apr 2020 17:08:25 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2004-00107.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{auvolat2019merkle,
  author={Auvolat, Alex and Taïani, François},
  booktitle={2019 38th Symposium on Reliable Distributed Systems (SRDS)},
  title={Merkle Search Trees: Efficient State-Based {CRDTs} in Open Networks},
  year={2019},
  volume={},
  number={},
  pages={221-22109},
  keywords={Merkle trees, search trees, CRDT, IoT, georeplicated systems, peer-to-peer, anti-entropy},
  doi={10.1109/SRDS47363.2019.00032}
}
@article{schiefer2022building,
  title={Building data-centric apps with a reactive relational database},
  journal={Programming Local-First Software Workshop 2022},
  author={Litt, Geoffrey and Schiefer, Nicholas and Schickling, Johannes and Jackson, Daniel},
  year={2022},
  month={June},
  url_paper={https://riffle.systems/essays/prelude}
}
@inproceedings{kleppmann2024bluesky,
  author = {Kleppmann, Martin and Frazee, Paul and Gold, Jake and Graber, Jay and Holmgren, Daniel and Ivy, Devin and Johnson, Jeromy and Newbold, Bryan and Volpert, Jaz},
  title = {Bluesky and the AT Protocol: Usable Decentralized Social Media},
  year = {2024},
  isbn = {9798400712524},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3694809.3700740},
  doi = {10.1145/3694809.3700740},
  abstract = {Bluesky is a new social network built upon the AT Protocol, a decentralized foundation for public social media. It was launched in private beta in February 2023, and has grown to over 10 million registered users by October 2024. In this paper we introduce the architecture of Bluesky and the AT Protocol, and explain how the technical design of Bluesky is informed by our goals: to enable decentralization by having multiple interoperable providers for every part of the system; to make it easy for   users to switch providers; to give users agency over the content they see; and to provide a simple user experience that does not burden users with complexity arising from the system's decentralized nature. The system's openness allows anybody to contribute to content moderation and community management, and we invite the research community to use Bluesky as a dataset and testing ground for new approaches in social media moderation.},
  booktitle = {Proceedings of the ACM Conext-2024 Workshop on the Decentralization of the Internet},
  pages = {1–7},
  numpages = {7},
  keywords = {decentralization, federation, social networks},
  location = {Los Angeles, CA, USA},
  series = {DIN '24}
}
@inproceedings{bftcrdts,
  author = {Kleppmann, Martin},
  title = {Making {CRDTs} {Byzantine} fault tolerant},
  year = {2022},
  isbn = {9781450392563},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3517209.3524042},
  doi = {10.1145/3517209.3524042},
  abstract = {It is often claimed that Conflict-free Replicated Data Types (CRDTs) ensure consistency of replicated data in peer-to-peer systems. However, peer-to-peer systems usually consist of untrusted nodes that may deviate from the specified protocol (i.e. exhibit Byzantine faults), and most existing CRDT algorithms cannot guarantee consistency in the presence of such faults. This paper shows how to adapt existing non-Byzantine CRDT algorithms and make them Byzantine fault-tolerant. The proposed scheme   can tolerate any number of Byzantine nodes (making it immune to Sybil attacks), guarantees Strong Eventual Consistency, and requires only modest changes to existing CRDT algorithms.},
  booktitle = {Proceedings of the 9th Workshop on Principles and Practice of Consistency for Distributed Data},
  pages = {8–15},
  numpages = {8},
  keywords = {optimistic replication, eventual consistency, CRDTs, Byzantine fault tolerance},
  location = {Rennes, France},
  series = {PaPoC '22}
}
@inproceedings{litt2023riffle,
  author = {Litt, Geoffrey and Schiefer, Nicholas and Schickling, Johannes and Jackson, Daniel},
  title = {Riffle: Reactive Relational State for Local-First Applications},
  year = {2023},
  isbn = {9798400701320},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3586183.3606801},
  doi = {10.1145/3586183.3606801},
  abstract = {The reactive paradigm for developing user interfaces promises both simplicity and scalability, but existing frameworks usually compromise one for the other. We present Riffle, a reactive state management system that achieves both simplicity and scalability by managing the entire state of a web application in a client-side persistent relational database. Data transformations over the application state are defined in a graph of reactive relational queries, providing developers with a simple   spreadsheet-like reactivity model. Domain state and UI state are unified within the same system, and efficient incremental query maintenance ensures the UI remains responsive. We present a formative case study of using Riffle to build a music management application with complex data and stringent performance requirements.},
  booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
  articleno = {76},
  numpages = {16},
  keywords = {Reactive Programming, Relational Databases, UI State Management},
  location = {San Francisco, CA, USA},
  series = {UIST '23}
}
@online{dittoinc,
  author = {{DittoLive Inc.}},
  title = {{DittoLive's} Homepage},
  year = 2025,
  url = {https://web.archive.org/web/20250613135524/https://www.ditto.com/},
  urldate = {2025-06-13}
}
@inbook{gupta1995maintenance,
  author = {Gupta, Ashish and Mumick, Inderpal Singh},
  title = {Maintenance of materialized views: problems, techniques, and applications},
  year = {1999},
  isbn = {0262571226},
  publisher = {MIT Press},
  address = {Cambridge, MA, USA},
  booktitle = {Materialized Views: Techniques, Implementations, and Applications},
  pages = {145–157},
  numpages = {13}
}
@inproceedings{gupta1993maintaining,
  author = {Gupta, Ashish and Mumick, Inderpal Singh and Subrahmanian, V. S.},
  title = {Maintaining views incrementally},
  year = {1993},
  isbn = {0897915925},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/170035.170066},
  doi = {10.1145/170035.170066},
  abstract = {We present incremental evaluation algorithms to compute changes to materialized views in relational and deductive database systems, in response to changes (insertions, deletions, and updates) to the relations. The view definitions can be in SQL or Datalog, and may use UNION, negation, aggregation (e.g. SUM, MIN), linear recursion, and general recursion.We first present a counting algorithm that tracks the number of alternative derivations (counts) for each derived tuple in a view. The algorithm   works with both set and duplicate semantics. We present the algorithm for nonrecursive views (with negation and aggregation), and show that the count for a tuple can be computed at little or no cost above the cost of deriving the tuple. The algorithm is optimal in that it computes exactly those view tuples that are inserted or deleted. Note that we store only the number of derivations, not the derivations themselves.We then present the Delete and Rederive algorithm, DRed, for incremental maintenance of   recursive views (negation and aggregation are permitted). The algorithm works by first deleting a superset of the tuples that need to be deleted, and then rederiving some of them. The algorithm can also be used when the view definition is itself altered.},
  booktitle = {Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data},
  pages = {157–166},
  numpages = {10},
  location = {Washington, D.C., USA},
  series = {SIGMOD '93}
}
@article{neumann2011efficiently,
  author = {Neumann, Thomas},
  title = {Efficiently compiling efficient query plans for modern hardware},
  year = {2011},
  issue_date = {June 2011},
  publisher = {VLDB Endowment},
  volume = {4},
  number = {9},
  issn = {2150-8097},
  url = {https://doi.org/10.14778/2002938.2002940},
  doi = {10.14778/2002938.2002940},
  abstract = {As main memory grows, query performance is more and more determined by the raw CPU costs of query processing itself. The classical iterator style query processing technique is very simple and exible, but shows poor performance on modern CPUs due to lack of locality and frequent instruction mispredictions. Several techniques like batch oriented processing or vectorized tuple processing have been proposed in the past to improve this situation, but even these techniques are frequently   out-performed by hand-written execution plans.In this work we present a novel compilation strategy that translates a query into compact and efficient machine code using the LLVM compiler framework. By aiming at good code and data locality and predictable branch layout the resulting code frequently rivals the performance of hand-written C++ code. We integrated these techniques into the HyPer main memory database system and show that this results in excellent query performance while requiring only modest   compilation time.},
  journal = {Proc. VLDB Endow.},
  month = jun,
  pages = {539–550},
  numpages = {12}
}
@article{zukowski2005monetdb,
  author = {Zukowski, Marcin and Boncz, Peter and Nes, Niels and Héman, Sándor},
  year = {2005},
  month = {01},
  pages = {17-22},
  title = {{MonetDB/X100 - A DBMS in the CPU cache}},
  volume = {28},
  journal = {IEEE Data Eng. Bull.}
}
@article{kersten2018everything,
  author = {Kersten, Timo and Leis, Viktor and Kemper, Alfons and Neumann, Thomas and Pavlo, Andrew and Boncz, Peter},
  title = {Everything you always wanted to know about compiled and vectorized queries but were afraid to ask},
  year = {2018},
  issue_date = {September 2018},
  publisher = {VLDB Endowment},
  volume = {11},
  number = {13},
  issn = {2150-8097},
  url = {https://doi.org/10.14778/3275366.3284966},
  doi = {10.14778/3275366.3284966},
  abstract = {The query engines of most modern database systems are either based on vectorization or data-centric code generation. These two state-of-the-art query processing paradigms are fundamentally different in terms of system structure and query execution code. Both paradigms were used to build fast systems. However, until today it is not clear which paradigm yields faster query execution, as many implementation-specific choices obstruct a direct comparison of architectures. In this paper, we   experimentally compare the two models by implementing both within the same test system. This allows us to use for both models the same query processing algorithms, the same data structures, and the same parallelization framework to ultimately create an apples-to-apples comparison. We find that both are efficient, but have different strengths and weaknesses. Vectorization is better at hiding cache miss latency, whereas data-centric compilation requires fewer CPU instructions, which benefits cache-resident   workloads. Besides raw, single-threaded performance, we also investigate SIMD as well as multi-core parallelization and different hardware architectures. Finally, we analyze qualitative differences as a guide for system architects.},
  journal = {Proc. VLDB Endow.},
  month = sep,
  pages = {2209–2222},
  numpages = {14}
}
@inproceedings{selinger1979access,
  author = {Selinger, P. Griffiths and Astrahan, M. M. and Chamberlin, D. D. and Lorie, R. A. and Price, T. G.},
  title = {Access path selection in a relational database management system},
  year = {1979},
  isbn = {089791001X},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/582095.582099},
  doi = {10.1145/582095.582099},
  abstract = {In a high level query and data manipulation language such as SQL, requests are stated non-procedurally, without reference to access paths. This paper describes how System R chooses access paths for both simple (single relation) and complex queries (such as joins), given a user specification of desired data as a boolean expression of predicates. System R is an experimental database management system developed to carry out research on the relational model of data. System R was designed and built   by members of the IBM San Jose Research Laboratory.},
  booktitle = {Proceedings of the 1979 ACM SIGMOD International Conference on Management of Data},
  pages = {23–34},
  numpages = {12},
  location = {Boston, Massachusetts},
  series = {SIGMOD '79}
}
@inproceedings{idris2017dynamic,
  author = {Idris, Muhammad and Ugarte, Martin and Vansummeren, Stijn},
  title = {The {Dynamic Yannakakis} Algorithm: Compact and Efficient Query Processing Under Updates},
  year = {2017},
  isbn = {9781450341974},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3035918.3064027},
  doi = {10.1145/3035918.3064027},
  abstract = {Modern computing tasks such as real-time analytics require refresh of query results under high update rates. Incremental View Maintenance (IVM) approaches this problem by materializing results in order to avoid recomputation. IVM naturally induces a trade-off between the space needed to maintain the materialized results and the time used to process updates. In this paper, we show that the full materialization of results is a barrier for more general optimization strategies. In particular, we   present a new approach for evaluating queries under updates. Instead of the materialization of results, we require a data structure that allows: (1) linear time maintenance under updates, (2) constant-delay enumeration of the output, (3) constant-time lookups in the output, while (4) using only linear space in the size of the database. We call such a structure a Dynamic Constant-delay Linear Representation (DCLR) for the query. We show that DYN, a dynamic version of the Yannakakis algorithm, yields DCLRs   for the class of free-connex acyclic CQs. We show that this is optimal in the sense that no DCLR can exist for CQs that are not free-connex acyclic. Moreover, we identify a sub-class of queries for which DYN features constant-time update per tuple and show that this class is maximal. Finally, using the TPC-H and TPC-DS benchmarks, we experimentally compare DYN and a higher-order IVM (HIVM) engine. Our approach is not only more efficient in terms of memory consumption (as expected), but is also consistently   faster in processing updates.},
  booktitle = {Proceedings of the 2017 ACM International Conference on Management of Data},
  pages = {1259–1274},
  numpages = {16},
  keywords = {incremental view maintenance, dynamic query processing, acyclic joins},
  location = {Chicago, Illinois, USA},
  series = {SIGMOD '17}
}
@inproceedings{green2007provenance,
  author = {Green, Todd J. and Karvounarakis, Grigoris and Tannen, Val},
  title = {Provenance semirings},
  year = {2007},
  isbn = {9781595936851},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/1265530.1265535},
  doi = {10.1145/1265530.1265535},
  abstract = {We show that relational algebra calculations for incomplete databases, probabilistic databases, bag semantics and why-provenance are particular cases of the same general algorithms involving semirings. This further suggests a comprehensive provenance representation that uses semirings of polynomials. We extend these considerations to datalog and semirings of formal power series. We give algorithms for datalog provenance calculation as well as datalog evaluation for incomplete and probabilistic   databases. Finally, we show that for some semirings containment of conjunctive queries is the same as for standard set semantics.},
  booktitle = {Proceedings of the Twenty-Sixth ACM SIGMOD-SIGACT-SIGART {Symposium on Principles of Database Systems}},
  pages = {31–40},
  numpages = {10},
  keywords = {data lineage, data provenance, datalog, formal power series, incomplete databases, probabilistic databases, semirings},
  location = {Beijing, China},
  series = {PODS '07}
}
@inbook{apt1988towards,
  author = {Apt, K. R. and Blair, H. A. and Walker, A.},
  title = {Towards a theory of declarative knowledge},
  year = {1988},
  isbn = {0934613400},
  publisher = {Morgan Kaufmann Publishers Inc.},
  address = {San Francisco, CA, USA},
  booktitle = {Foundations of Deductive Databases and Logic Programming},
  pages = {89–148},
  numpages = {60}
}
@article{kahn1962topological,
  author = {Kahn, A. B.},
  title = {Topological sorting of large networks},
  year = {1962},
  issue_date = {Nov. 1962},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {5},
  number = {11},
  issn = {0001-0782},
  url = {https://doi.org/10.1145/368996.369025},
  doi = {10.1145/368996.369025},
  abstract = {Topological Sorting is a procedure required for many problems involving analysis of networks. An example of one such problem is PERT. The present paper presents a very general method for obtaining topological order. It permits treatment of larger networks than can be handled on present procedures and achieves this with greater efficiency. Although the procedure can be adapted to any machine, it is discussed in terms of the 7090. A PERT network of 30,000 activities can be ordered in less than   one hour of machine time.  The method was developed as a byproduct of procedure needed by Westinghouse, Baltimore. It has not been programmed and at present there are no plans to implement it. In regard to the techniques described, Westinghouse's present and anticipated needs are completely served by the Lockheed program, which is in current use.},
  journal = {Commun. ACM},
  month = nov,
  pages = {558–562},
  numpages = {5}
}
@inproceedings{verifx,
  author = {De Porre, Kevin and Ferreira, Carla and Gonzalez Boix, Elisa},
  title = {{VeriFx: Correct Replicated Data Types for the Masses}},
  booktitle = {37th European Conference on Object-Oriented Programming (ECOOP 2023)},
  pages = {9:1--9:45},
  series = {Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN = {978-3-95977-281-5},
  ISSN = {1868-8969},
  year = {2023},
  volume = {263},
  editor = {Ali, Karim and Salvaneschi, Guido},
  publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address = {Dagstuhl, Germany},
  URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ECOOP.2023.9},
  URN = {urn:nbn:de:0030-drops-182028},
  doi = {10.4230/LIPIcs.ECOOP.2023.9},
  annote = {Keywords: distributed systems, eventual consistency, replicated data types, verification}
}
@article{propel,
  author = {Zakhour, George and Weisenburger, Pascal and Salvaneschi, Guido},
  title = {Type-Checking {CRDT} Convergence},
  year = {2023},
  issue_date = {June 2023},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {7},
  number = {PLDI},
  url = {https://doi.org/10.1145/3591276},
  doi = {10.1145/3591276},
  abstract = {Conflict-Free Replicated Data Types (CRDTs) are a recent approach for keeping replicated data consistent while guaranteeing the absence of conflicts among replicas. For correct operation, CRDTs rely on a merge function that is commutative, associative and idempotent. Ensuring that such algebraic properties are satisfied by implementations, however, is left to the programmer, resulting in a process that is complex and error-prone. While techniques based on testing, automatic verification of a   model, and mechanized or handwritten proofs are available, we lack an approach that is able to verify such properties on concrete CRDT implementations.   In this paper, we present Propel, a programming language with a type system that captures the algebraic properties required by a correct CRDT implementation. The Propel type system deduces such properties by case analysis and induction: sum types guide the case analysis and algebraic properties in function types enable induction for free. Propel’s key   feature is its capacity to reason about algebraic properties (a) in terms of rewrite rules and (b) to derive the equality or inequality of expressions from the properties. We provide an implementation of Propel as a Scala embedding, we implement several CRDTs, verify them with Propel and compare the verification process with four state-of-the-art verification tools. Our evaluation shows that Propel is able to automatically deduce the properties that are relevant for common CRDT implementations found in   open-source libraries even in cases in which competitors timeout.},
  journal = {Proc. ACM Program. Lang.},
  month = jun,
  articleno = {162},
  numpages = {24},
  keywords = {Verification, Type Systems, Conflict-Free Replicated Data Types}
}
@article{lore,
  author = {Haas, Julian and Mogk, Ragnar and Yanakieva, Elena and Bieniusa, Annette and Mezini, Mira},
  title = {{LoRe}: A Programming Model for Verifiably Safe Local-first Software},
  year = {2024},
  issue_date = {March 2024},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {46},
  number = {1},
  issn = {0164-0925},
  url = {https://doi.org/10.1145/3633769},
  doi = {10.1145/3633769},
  abstract = {Local-first software manages and processes private data locally while still enabling collaboration between multiple parties connected via partially unreliable networks. Such software typically involves interactions with users and the execution environment (the outside world). The unpredictability of such interactions paired with their decentralized nature make reasoning about the correctness of local-first software a challenging endeavor. Yet, existing solutions to develop local-first software do not provide support for automated safety guarantees and instead expect developers to reason about concurrent interactions in an environment with unreliable network conditions. We propose LoRe, a programming model and compiler that automatically verifies developer-supplied safety properties for local-first applications. LoRe combines the declarative data flow of reactive programming with static analysis and verification techniques to precisely determine concurrent interactions that violate safety invariants and to selectively employ strong consistency through coordination where required. We propose a formalized proof principle and demonstrate how to automate the process in a prototype implementation that outputs verified executable code. Our evaluation shows that LoRe simplifies the development of safe local-first software when compared to state-of-the-art approaches and that verification times are acceptable.},
  journal = {ACM Trans. Program. Lang. Syst.},
  month = jan,
  articleno = {2},
  numpages = {26},
  keywords = {Local-first software, reactive programming, invariants, consistency, automatic verification}
}
@article{bailis2014coordination,
  author = {Bailis, Peter and Fekete, Alan and Franklin, Michael J. and Ghodsi, Ali and Hellerstein, Joseph M. and Stoica, Ion},
  title = {Coordination avoidance in database systems},
  year = {2014},
  issue_date = {November 2014},
  publisher = {VLDB Endowment},
  volume = {8},
  number = {3},
  issn = {2150-8097},
  url = {https://doi.org/10.14778/2735508.2735509},
  doi = {10.14778/2735508.2735509},
  abstract = {Minimizing coordination, or blocking communication between concurrently executing operations, is key to maximizing scalability, availability, and high performance in database systems. However, uninhibited coordination-free execution can compromise application correctness, or consistency. When is coordination necessary for correctness? The classic use of serializable transactions is sufficient to maintain correctness but is not necessary for all applications, sacrificing potential scalability. In this paper, we develop a formal framework, invariant confluence, that determines whether an application requires coordination for correct execution. By operating on application-level invariants over database states (e.g., integrity constraints), invariant confluence analysis provides a necessary and sufficient condition for safe, coordination-free execution. When programmers specify their application invariants, this analysis allows databases to coordinate only when anomalies that might violate invariants are possible. We analyze the invariant confluence of common invariants and operations from real-world database systems (i.e., integrity constraints) and applications and show that many are invariant confluent and therefore achievable without coordination. We apply these results to a proof-of-concept coordination-avoiding database prototype and demonstrate sizable performance gains compared to serializable execution, notably a 25-fold improvement over prior TPC-C New-Order performance on a 200 server cluster.},
  journal = {Proc. VLDB Endow.},
  month = nov,
  pages = {185–196},
  numpages = {12}
}
@book{nystrom2021crafting,
  title={Crafting interpreters},
  author={Nystrom, Robert},
  year={2021},
  publisher={Genever Benning}
}
@article{moveop1,
  author={Kleppmann, Martin and Mulligan, Dominic P. and Gomes, Victor B. F. and Beresford, Alastair R.},
  journal={IEEE Transactions on Parallel and Distributed Systems},
  title={A Highly-Available Move Operation for Replicated Trees},
  year={2022},
  volume={33},
  number={7},
  pages={1711-1724},
  keywords={Internet;Synchronization;Computer bugs;XML;Software;Drives;Data models;Conflict-free replicated data types (CRDTs);formal verification;distributed filesystems;distributed collaboration},
  doi={10.1109/TPDS.2021.3118603}
}
@inproceedings{moveop2,
  author = {Da, Liangrun and Kleppmann, Martin},
  title = {Extending {JSON CRDTs} with Move Operations},
  year = {2024},
  isbn = {9798400705441},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3642976.3653030},
  doi = {10.1145/3642976.3653030},
  abstract = {Conflict-Free Replicated Data Types (CRDTs) for JSON allow users to concurrently update a JSON document and automatically merge the updates into a consistent state. Moving a subtree in a map or reordering elements in a list within a JSON CRDT is challenging: naive merge algorithms may introduce unexpected results such as duplicates or cycles. In this paper, we introduce an algorithm for move operations in a JSON CRDT that handles the interaction with concurrent non-move operations, and uses novel optimisations to improve performance. We plan to integrate this algorithm into the Automerge CRDT library.},
  booktitle = {Proceedings of the 11th Workshop on Principles and Practice of Consistency for Distributed Data},
  pages = {8–14},
  numpages = {7},
  keywords = {conflict-free replicated data types, replica consistency, JSON, tree data structures, move operation},
  location = {Athens, Greece},
  series = {PaPoC '24}
}
@inproceedings{logoot,
  author={Weiss, Stephane and Urso, Pascal and Molli, Pascal},
  booktitle={2009 29th IEEE International Conference on Distributed Computing Systems},
  title={Logoot: A Scalable Optimistic Replication Algorithm for Collaborative Editing on P2P Networks},
  year={2009},
  volume={},
  number={},
  pages={404-412},
  keywords={Radiofrequency interference;Wikipedia;Scalability;International collaboration;Costs;Control systems;Convergence;Distributed computing;Collaborative tools;Online Communities/Technical Collaboration;P2P;Collaborative Editing},
  doi={10.1109/ICDCS.2009.75}
}
@inproceedings{treedoc,
  author={Preguica, Nuno and Marques, Joan Manuel and Shapiro, Marc and Letia, Mihai},
  booktitle={2009 29th IEEE International Conference on Distributed Computing Systems},
  title={A Commutative Replicated Data Type for Cooperative Editing},
  year={2009},
  volume={},
  number={},
  pages={395-403},
  keywords={Binary trees;Concurrency control;History;Convergence;Concurrent computing;Compaction;Distributed computing;Delay;Automatic control;Writing;commutative replicated data type;distributed algorithms;replicated data;co-operative editing;dense identifier space},
  doi={10.1109/ICDCS.2009.20}
}
@article{rga,
  author = {Roh, Hyun-Gul and Jeon, Myeongjae and Kim, Jin-Soo and Lee, Joonwon},
  title = {Replicated abstract data types: Building blocks for collaborative applications},
  year = {2011},
  issue_date = {March, 2011},
  publisher = {Academic Press, Inc.},
  address = {USA},
  volume = {71},
  number = {3},
  issn = {0743-7315},
  url = {https://doi.org/10.1016/j.jpdc.2010.12.006},
  doi = {10.1016/j.jpdc.2010.12.006},
  abstract = {For distributed applications requiring collaboration, responsive and transparent interactivity is highly desired. Though such interactivity can be achieved with optimistic replication, maintaining replica consistency is difficult. To support efficient implementations of collaborative applications, this paper extends a few representative abstract data types (ADTs), such as arrays, hash tables, and growable arrays (or linked lists), into replicated abstract data types (RADTs). In RADTs, a shared   ADT is replicated and modified with optimistic operations. Operation commutativity and precedence transitivity are two principles enabling RADTs to maintain consistency despite different execution orders. Especially, replicated growable arrays (RGAs) support insertion/deletion/update operations. Over previous approaches to the optimistic insertion and deletion, RGAs show significant improvement in performance, scalability, and reliability.},
  journal = {J. Parallel Distrib. Comput.},
  month = mar,
  pages = {354–368},
  numpages = {15},
  keywords = {Collaboration, Distributed data structures, Optimistic algorithm, Optimistic replication, Replicated abstract data types}
}
@misc{fugue,
  title={The Art of the Fugue: Minimizing Interleaving in Collaborative Text Editing},
  author={Matthew Weidner and Martin Kleppmann},
  year={2023},
  eprint={2305.00583},
  archivePrefix={arXiv},
  primaryClass={cs.DC},
  url={https://arxiv.org/abs/2305.00583},
}
@inproceedings{egwalker,
  author = {Gentle, Joseph and Kleppmann, Martin},
  title = {Collaborative Text Editing with Eg-walker: Better, Faster, Smaller},
  year = {2025},
  isbn = {9798400711961},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3689031.3696076},
  doi = {10.1145/3689031.3696076},
  abstract = {Collaborative text editing algorithms allow several users to concurrently modify a text file, and automatically merge concurrent edits into a consistent state. Existing algorithms fall in two categories: Operational Transformation (OT) algorithms are slow to merge files that have diverged substantially due to offline editing; CRDTs are slow to load and consume a lot of memory. We introduce Eg-walker, a collaboration algorithm for text that avoids these weaknesses. Compared to existing CRDTs, it   consumes an order of magnitude less memory in the steady state, and loading a document from disk is orders of magnitude faster. Compared to OT, merging long-running branches is orders of magnitude faster. In the worst case, the merging performance of Eg-walker is comparable with existing CRDT algorithms. Eg-walker can be used everywhere CRDTs are used, including peer-to-peer systems without a central server. By offering performance that is competitive with centralised algorithms, our result paves the way   towards the widespread adoption of peer-to-peer collaboration software.},
  booktitle = {Proceedings of the Twentieth European Conference on Computer Systems},
  pages = {311–328},
  numpages = {18},
  keywords = {CRDTs, collaborative text editing, operational transformation, strong eventual consistency},
  location = {Rotterdam, Netherlands},
  series = {EuroSys '25}
}
@inproceedings{souffle,
  author = {Scholz, Bernhard and Jordan, Herbert and Suboti\'{c}, Pavle and Westmann, Till},
  title = {On fast large-scale program analysis in Datalog},
  year = {2016},
  isbn = {9781450342414},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/2892208.2892226},
  doi = {10.1145/2892208.2892226},
  abstract = {Designing and crafting a static program analysis is challenging due to the complexity of the task at hand. Among the challenges are modelling the semantics of the input language, finding suitable abstractions for the analysis, and handwriting efficient code for the analysis in a traditional imperative language such as C++. Hence, the development of static program analysis tools is costly in terms of development time and resources for real world languages. To overcome, or at least alleviate the   costs of developing a static program analysis, Datalog has been proposed as a domain specific language (DSL). With Datalog, a designer expresses a static program analysis in the form of a logical specification. While a domain specific language approach aids in the ease of development of program analyses, it is commonly accepted that such an approach has worse runtime performance than handcrafted static analysis tools. In this work, we introduce a new program synthesis methodology for Datalog specifications   to produce highly efficient monolithic C++ analyzers. The synthesis technique requires the re-interpretation of the semi-naive evaluation as a scaffolding for translation using partial evaluation. To achieve high-performance, we employ staged-compilation techniques and specialize the underlying relational data structures for a given Datalog specification. Experimentation on benchmarks for large-scale program analysis validates the superior performance of our approach over available Datalog tools and   demonstrates our competitiveness with state-of-the-art handcrafted tools.},
  booktitle = {Proceedings of the 25th International Conference on Compiler Construction},
  pages = {196–206},
  numpages = {11},
  keywords = {Compiler, Datalog, Program Synthesis, Static Program Analysis},
  location = {Barcelona, Spain},
  series = {CC '16}
}
@inproceedings{dynamicdatalog,
  author       = {Bruno Rucy Carneiro Alves de Lima and Kalmer Apinis and Merlin Kramer and Kristopher K. Micinski},
  editor       = {Mario Alviano and Matthias Lanzinger},
  title        = {Incremental Evaluation of Dynamic Datalog Programs as a Higher-order {DBSP} Program},
  booktitle    = {Proceedings 5th International Workshop on the Resurgence of Datalog in Academia and Industry (Datalog-2.0 2024) co-located with the 17th International Conference on Logic Programming and Nonmonotonic Reasoning {(LPNMR} 2024), Dallas, Texas, USA, October 11, 2024},
  series       = {{CEUR} Workshop Proceedings},
  volume       = {3801},
  pages        = {2--16},
  publisher    = {CEUR-WS.org},
  year         = {2024},
  url          = {https://ceur-ws.org/Vol-3801/paper1.pdf},
  timestamp    = {Fri, 08 Nov 2024 15:21:04 +0100},
  biburl       = {https://dblp.org/rec/conf/datalog/LimaAKM24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{ascent,
  author = {Sahebolamri, Arash and Gilray, Thomas and Micinski, Kristopher},
  title = {Seamless deductive inference via macros},
  year = {2022},
  isbn = {9781450391832},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3497776.3517779},
  doi = {10.1145/3497776.3517779},
  abstract = {We present an approach to integrating state-of-art bottom-up logic programming within the Rust ecosystem, demonstrating it with Ascent, an extension of Datalog that performs well against comparable systems. Rust’s powerful macro system permits Ascent to be compiled uniformly with the Rust code it’s embedded in and to interoperate with arbitrary user-defined components written in Rust, addressing a challenge in real-world use of logic programming languages: the fact that logical programs are   parts of bigger software systems and need to interoperate with other components written in imperative programming languages. We leverage Rust’s trait system to extend Datalog semantics with non-powerset lattices, much like Flix, and with user-defined data types much like Formulog and Souffle. We use Ascent to re-implement the Rust borrow checker, a static analysis required by the Rust compiler. We evaluate our performance against Datafrog, Flix, and Souffl\'{e} using the borrow checker and other   benchmarks, observing comparable performance to Datafrog and Souffl\'{e}, and speedups of around two orders of magnitude compared to Flix.},
  booktitle = {Proceedings of the 31st ACM SIGPLAN International Conference on Compiler Construction},
  pages = {77–88},
  numpages = {12},
  keywords = {Static Analysis, Rust, Program Analysis, Logic Programming, Datalog, Ascent},
  location = {Seoul, South Korea},
  series = {CC 2022}
}
@article{flix,
  author = {Madsen, Magnus and Yee, Ming-Ho and Lhot\'{a}k, Ond\v{r}ej},
  title = {From Datalog to flix: a declarative language for fixed points on lattices},
  year = {2016},
  issue_date = {June 2016},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {51},
  number = {6},
  issn = {0362-1340},
  url = {https://doi.org/10.1145/2980983.2908096},
  doi = {10.1145/2980983.2908096},
  abstract = {We present Flix, a declarative programming language for specifying and solving least fixed point problems, particularly static program analyses. Flix is inspired by Datalog and extends it with lattices and monotone functions. Using Flix, implementors of static analyses can express a broader range of analyses than is currently possible in pure Datalog, while retaining its familiar rule-based syntax. We define a model-theoretic semantics of Flix as a natural extension of the Datalog semantics.   This semantics captures the declarative meaning of Flix programs without imposing any specific evaluation strategy. An efficient strategy is semi-naive evaluation which we adapt for Flix. We have implemented a compiler and runtime for Flix, and used it to express several well-known static analyses, including the IFDS and IDE algorithms. The declarative nature of Flix clearly exposes the similarity between these two algorithms.},
  journal = {SIGPLAN Not.},
  month = jun,
  pages = {194–208},
  numpages = {15},
  keywords = {Datalog, logic programming, static analysis}
}
@inproceedings{ratelesssetreconc,
  author = {Yang, Lei and Gilad, Yossi and Alizadeh, Mohammad},
  title = {Practical Rateless Set Reconciliation},
  year = {2024},
  isbn = {9798400706141},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3651890.3672219},
  doi = {10.1145/3651890.3672219},
  abstract = {Set reconciliation, where two parties hold fixed-length bit strings and run a protocol to learn the strings they are missing from each other, is a fundamental task in many distributed systems. We present Rateless Invertible Bloom Lookup Tables (Rateless IBLTs), the first set reconciliation protocol, to the best of our knowledge, that achieves low computation cost and near-optimal communication cost across a wide range of scenarios: set differences of one to millions, bit strings of a few bytes   to megabytes, and workloads injected by potential adversaries. Rateless IBLT is based on a novel encoder that incrementally encodes the set difference into an infinite stream of coded symbols, resembling rateless error-correcting codes. We compare Rateless IBLT with state-of-the-art set reconciliation schemes and demonstrate significant improvements. Rateless IBLT achieves 3--4\texttimes{} lower communication cost than non-rateless schemes with similar computation cost, and 2--2000\texttimes{} lower   computation cost than schemes with similar communication cost. We show the real-world benefits of Rateless IBLT by applying it to synchronize the state of the Ethereum blockchain, and demonstrate 5.6\texttimes{} lower end-to-end completion time and 4.4\texttimes{} lower communication cost compared to the system used in production.},
  booktitle = {Proceedings of the ACM SIGCOMM 2024 Conference},
  pages = {595–612},
  numpages = {18},
  keywords = {set reconciliation, rateless codes, universal codes, data synchronization, randomized algorithms},
  location = {Sydney, NSW, Australia},
  series = {ACM SIGCOMM '24}
}
@misc{rangebasedsetreconc,
  title={Range-Based Set Reconciliation},
  author={Aljoscha Meyer},
  year={2023},
  eprint={2212.13567},
  archivePrefix={arXiv},
  primaryClass={cs.CR},
  url={https://arxiv.org/abs/2212.13567},
}
@inproceedings{timestamped-insertion-trees,
  author = {Attiya, Hagit and Burckhardt, Sebastian and Gotsman, Alexey and Morrison, Adam and Yang, Hongseok and Zawirski, Marek},
  title = {Specification and Complexity of Collaborative Text Editing},
  year = {2016},
  isbn = {9781450339643},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/2933057.2933090},
  doi = {10.1145/2933057.2933090},
  abstract = {Collaborative text editing systems allow users to concurrently edit a shared document, inserting and deleting elements (e.g., characters or lines). There are a number of protocols for collaborative text editing, but so far there has been no precise specification of their desired behavior, and several of these protocols have been shown not to satisfy even basic expectations. This paper provides a precise specification of a replicated list object, which models the core functionality of replicated   systems for collaborative text editing. We define a strong list specification, which we prove is implemented by an existing protocol, as well as a weak list specification, which admits additional protocol behaviors.A major factor determining the efficiency and practical feasibility of a collaborative text editing protocol is the space overhead of the metadata that the protocol must maintain to ensure correctness. We show that for a large class of list protocols, implementing either the strong or the weak   list specification requires a metadata overhead that is at least linear in the number of elements deleted from the list. The class of protocols to which this lower bound applies includes all list protocols that we are aware of, and we show that one of these protocols almost matches the bound.},
  booktitle = {Proceedings of the 2016 ACM Symposium on Principles of Distributed Computing},
  pages = {259–268},
  numpages = {10},
  keywords = {eventual consistency, collaborative text editing},
  location = {Chicago, Illinois, USA},
  series = {PODC '16}
}
@inproceedings{causal-trees,
  author = {Grishchenko, Victor},
  title = {Deep hypertext with embedded revision control implemented in regular expressions},
  year = {2010},
  isbn = {9781450300568},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/1832772.1832777},
  doi = {10.1145/1832772.1832777},
  abstract = {While text versioning was definitely a part of the original hypertext concept [21, 36, 44], it is rarely considered in this context today. Still, we know that revision control underlies the most exciting social co-authoring projects of the today's Internet, namely the Wikipedia and the Linux kernel. With an intention to adapt the advanced revision control technologies and practices to the conditions of the Web, the paper reconsiders some obsolete assumptions and develops a new versioned text   format perfectly processable with standard regular expressions (PCRE [6]). The resulting deep hypertext model allows instant access to past/concurrent versions, authorship, changes; enables deep links to reference changing parts of a changing text. Effectively, it allows distributed and real-time revision control on the Web, implementing the vision of co-evolution and mutation exchange among multiple competing versions of the same text.},
  booktitle = {Proceedings of the 6th International Symposium on Wikis and Open Collaboration},
  articleno = {3},
  numpages = {10},
  location = {Gdansk, Poland},
  series = {WikiSym '10}
}
