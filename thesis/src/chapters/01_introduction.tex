% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Introduction}\label{ch:intro}

\acp{CRDT} refer to a class of data structures that allow replicas in a distributed
system to agree on a shared state without any coordination of reads and writes
to the data structure, i.e., they can be served from the local state of a replica.
This allows for offline writes at each replica.
In case of concurrent writes, replicas are guaranteed to converge to the same state,
if their ``knowledge'' is based on the same set of writes.
This guarantee is what renders defining correct \acp{CRDT} challenging.
Currently, \acp{CRDT} are either implemented (1) as an object-oriented library
in an imperative programming language exposing a fixed API~\cite{automerge,yjs},
or implemented (2) using formal verification techniques,
sometimes exposed in a domain-specific language,
which then guarantee their convergence~\cite{verifx,lore}.
The former approach requires proving that the \ac{CRDT} algorithm
(and its implementation) is commutative when applying concurrent writes,
which is a subtle and error-prone task~\cite{gomes2017verifying,kleppmann2022assessing}.
The latter approach either requires lots of manual effort and expertise in formal
verification~\cite{gomes2017verifying},
and/or working with restricted domain-specific languages,
sometimes not expressive enough to express the desired \ac{CRDT}.
For instance, it is still an open problem to define a list \ac{CRDT} in VeriFx.

This leaves application developers wanting to use \acp{CRDT} in their applications
facing an unfortunate trade-off:
Either they use an existing \ac{CRDT} library, but cannot define their own \acp{CRDT}
tailored to their specific use case,
or they define their own \acp{CRDT} but have to invest significant efforts
in formally verifying it or learning a domain-specific language.
Previous work~\cite{kleppmann2018data} has proposed Datalog as a domain-specific
language to express \acp{CRDT} as queries over a set of operations.
Datalog's deterministic nature guarantees convergence for replicas executing it
on the same set of operations.
While still being a restricted language, Datalog may be more expressive
and better known than a custom domain-specific language.
Yet, so far the idea has only been hypothesized.
This work aims to put the idea into practice by exploring the feasability of
expressing \acp{CRDT} as Datalog queries through:

% TODO: More explicit forward-referencing.
\begin{itemize}
	\item \textbf{Implementing a query engine} which can execute queries
	      represented in an \ac{IR} (\ref{sec:incremental-query-engine}).
	      The \ac{IR} works on top of operators from relational algebra, e.g.,
	      joins, projections, and selections.
	      The engine uses \ac{IVM}, by leveraging the recently released DBSP
	      framework~\cite{budiu2025dbsp}, to incrementally maintain the state
	      of a query over a stream of updates.
	\item \textbf{Defining and implementing a Datalog dialect} (\ref{sec:datalog-frontend}),
	      powerful enough to express \acp{CRDT} as queries.
	      The dialect includes support for recursion and negation
	      and is transpiled (\ref{sec:datalog-to-relational-algebra})
	      to the query engine's \ac{IR}.
	\item \textbf{Providing \ac{CRDT} definitions} of
	      a \ac{MVR} key-value store (\ref{sec:motivating-example}),
	      a list (\ref{sec:crdts-as-queries}),
	      and a causal broadcast (\ref{sec:advanced_example}) in my Datalog dialect.
	      \ref{sec:benchmarks} evaluates their performance in two settings:
	      (1) simulating an application restart by feeding in all updates to
	      the \ac{CRDT} at once, and (2) simulating near-real-time collaboration
	      by feeding in recent updates on top of an existing state.
\end{itemize}

Ideally, this different approach to \acp{CRDT} may move them closer to the power,
guarantees and flexibility of database systems.
The higher abstraction of a query language better supports the decoupling from
logical and physical data representations than object-oriented APIs.
Moreover, higher abstractions allow for optimizations without breaking changes,
something relational databases have benefitted from over the years and has
arguably contributed towards their widespread adoption.
The data stored in \acp{CRDT} can benefit from the durability guarantees of
database systems, which are often not provided by \ac{CRDT} libraries.

% TODO: Maybe add the read finality issue of \acp{CRDT} here and cite with
% \cite{laddad2022keep}.

Conversely, database systems can be introduced to coordination-free environments.
In exchange for some guarantees, which cannot be upheld in such environments,
e.g. primary key constraints~\cite{bailis2014coordination},
coordination-free database systems can offer ultimate availability:
As long as at least one replica is alive, the database remains available.
This property can be useful in contexts where a system must be resilient
against network partitions.
For instance, a manufacturing processes may not afford to stop an entire
production facility just because some server is not available.
Although \acp{CRDT} are mostly discussed in the context of collaborative
applications, they are not limited to this domain:
Companies like Ditto~\cite{ditto} serve use cases powered by \acp{CRDT}
in manufacturing, aviation, gastronomy and defence sectors.

Applications may benefit from \ac{IVM} insofar that they receive updates
to the views defined by their queries instead of the full state.
That way, the idea of functional reactive programming can be extended from
the \ac{GUI} to the whole application stack, including the database layer.
The application can then be considered a reactive, pure function
of some state captured in a ground truth~\cite{litt2023riffle}.
Furthermore, showing data changes, e.g. diffs, to the user is naturally supported
without having to (ab)use a database's write-ahead log or similar change
data capture mechanisms.

\section{Motivating Example: A Key-Value Store as a Query}\label{sec:motivating-example}

This example demonstrates how a key value store,
consisting of \acp{MVR}, can be expressed with a query language.
A \ac{MVR} is a generalization of a \ac{LWWR}.
Unlike the latter, a \ac{MVR} exposes conflicting values to the application
as a consequence of concurrent writes to the register.
Therefore, a concurrency detection mechanism is required.
For this example, I use causal histories in which every operation specifies
a set of predecessor operations that it causally depends on.
Version vectors are another mechanism to detect concurrency
but they do not play as nice with relational data models.

I use two relations (\acp{EDBP} in Datalog terminology) to store the
operations on the registers of the key-value store.
The \code{set} relation contains a log of all operations
that ever happened to the key-value store.
The \code{pred} relation stores the causal dependencies between the operations.
The schema of both relations and some example data is shown in
\ref{fig:mvr-store-pred,fig:mvr-store-set}.
In operation-based \acp{CRDT}, a pair of \code{ReplicaId} and \code{Counter} values
(abbreviated as \code{RepId} and \code{Ctr}, respectively) is frequently used
to uniquely identify an operation.
The \code{ReplicaId} is a unique identifier for the replica that performed the
operation, and the \code{Counter} is essentially a Lamport clock~\cite{lamport2019time}.
Lamport clocks are useful to order concurrent operations on a register.
Having each replica draw a \code{ReplicaId} randomly from a sufficiently large space
such that the probability of a collision is negligible,
this scheme allows replicas to generate unique identifiers without a central authority.

\input{figures/mvr_store_relations.tex}

The causal history of the operations is illustrated on a logical level
in \ref{fig:causal-history-k1,fig:causal-history-k2}.
The edges represent the entries of the \code{pred} relation and a node's
\setop{Counter}{ReplicaId}{Key}{Value} label denotes a tuple of the \code{set}
relation.
To obtain the state of the key-value store, the following set must be computed:

\begin{align*}
	\var{mvrStore} = \{ (\var{Key}, \var{Value}) \mid
	 & (\var{RepId}, \var{Ctr}, \var{Key}, \var{Value}) \in \var{set}                      \\
	 & \land \nexists (\var{FromRepId}, \var{FromCtr}, \var{\_}, \var{\_}) \in \var{pred}: \\
	 & \var{RepId} = \var{FromRepId} \land \var{Ctr} = \var{FromCtr} \}
\end{align*}

Intuitively, the query selects all key-value pairs from the \code{set} relation
that have not been overwritten.
The result is \(\{ (k_1, y), (k_1, z), (k_2, c)\}\) because other assigned values
(\(x\) for \(k_1\); \(a, b\) for \(k_2\)) have been overwritten by later operations.
\ref{code:mvr-store-datalog} shows a Datalog query that computes the state of the
\ac{MVR} key-value store.
Its formulation resembles the mathematical notation above and uses the additional
``overwritten'' predicate to make it more readable.
The query can also be expressed in SQL, and I demonstrate two variants.
The first one in \ref{code:mvr-store-sql-left-join} uses a \code{LEFT JOIN}
and a \code{null} filter.
The second one in \ref{code:mvr-store-sql-subquery} uses a subquery
and negative set inclusion, to align the SQL query closer with the mathematical
notation.

\begin{figure}[htpb]
	\centering

	\begin{subfigure}[b]{\textwidth}
		% \begin{tabular}{c}
		\begin{lstlisting}[keepspaces]
overwritten(RepId, Ctr) :- pred(RepId, Ctr, _, _).
mvrStore(Key, Value)    :- set(RepId, Ctr, Key, Value),
                           not overwritten(RepId, Ctr).\end{lstlisting}
		% \end{tabular}
		\caption{The \ac{MVR} key-value store in Datalog.}\label{code:mvr-store-datalog}
	\end{subfigure}

	\vspace{1em}

	\begin{subfigure}[b]{\textwidth}
		% \begin{tabular}{c}
		\begin{lstlisting}[language=SQL]
SELECT key, value
FROM set LEFT JOIN pred ON set.RepId = pred.FromRepId
                        AND set.Ctr = pred.FromCtr
WHERE pred.FromRepId IS NULL;
        \end{lstlisting}
		% \end{tabular}
		\caption{The \ac{MVR} key-value store in SQL using a left join.}\label{code:mvr-store-sql-left-join}
	\end{subfigure}

	\vspace{1em}

	\begin{subfigure}[b]{\textwidth}
		% \begin{tabular}{c}
		\begin{lstlisting}[language=SQL]
WITH overwritten AS (SELECT FromRepId, FromCtr FROM pred)
SELECT key, value FROM set WHERE (RepId, Ctr) NOT IN overwritten;
        \end{lstlisting}
		% \end{tabular}
		\caption{The \ac{MVR} key-value store in SQL using a subquery and set difference.}\label{code:mvr-store-sql-subquery}
	\end{subfigure}

	\caption{The \ac{MVR} key-value store in Datalog and SQL.}\label{code:mvr-store}
\end{figure}

These examples demonstrate how little code is required to express a relatively
simple \ac{CRDT} as a query.
Unlike hand-coding them in an imperative programming language,
this approach is more approachable for developers familiar with query languages.
While for this example, the SQL queries are not too far off from the mathematical
notation, the next section shows that this is not always the case and motivates
why I turn towards Datalog as a query language in this work.

\section{Advanced Example: Respecting Causal Order}\label{sec:advanced_example}

\input{figures/causal_issue.tex}

Without the assumption of a causal broadcast,
the example from \autoref{sec:motivating-example} is not a proper \ac{MVR} \ac{CRDT},
as it does not respect the causal order of updates in case updates are delivered
out-of-order.
To illustrate this issue, consider \autoref{fig:causal_issue} from the
perspective of replica \(r_2\) and limited to register \(k_1\).
Initially, \(r_2\) is in the familiar state from \autoref{fig:causal-history-k1}.
Then, write \(w_2\) from replica \(r_1\) is delivered to \(r_2\) although its
causal dependency \(w_1\) has not been delivered yet.
At this point, the query from \autoref{sec:motivating-example} would return
\(\{ (k_1, y_1), (k_1, z), (k_1, y_3)\} \)
but the correct result respecting causal order is
\(\{ (k_1, y_1), (k_1, z) \}\).
The value \(y_3\) is delivered too early by eagerly applying the write \(w_2\)
without awaiting its causal dependency \(w_1\) first.
If \(w_1\) is eventually delivered, the query ``jumps'' to the result
\( \{ (k_1, y_3) \} \), skipping the intermediate state
that overwrites the conflicting values \(y_1\) and \(z\) with \(y_2\).
This falsely suggests that the value \(y_3\) suddenly overwrote its previously
reported siblings \(y_1\) and \(z\).

To prevent this, the query has to detect such ``gaps'' in the causal history.
Hence, the problem of causal delivery is equivalent to a graph reachability
problem: Which nodes are reachable from the set of root nodes?
\ref{code:mvr-crdt-datalog} extends the query from \autoref{sec:motivating-example}
with a causal broadcast expressed in Datalog.
It additionally introduces the four predicates, \code{overwrites}, \code{isRoot},
\code{isLeaf}, and \code{isCausallyReady}, to only consider operations
which are causally ready, to derive the state of the key-value store.
The \code{overwrites} predicate is analogous to the \code{overwritten} predicate.
The \code{isRoot} predicate captures the root nodes of the causal history,
and the \code{isLeaf} predicate captures the leaf nodes of the causal history.
The \code{isCausallyReady} predicate is defined recursively and captures
the transitive closure of the \code{pred} relation,
if starting from the root nodes of the causal history.
I return to the computation of the transitive closure in \ref{ch:background} to
explain the semantics of Datalog.
Moreover, I use the \ac{MVR} \ac{CRDT} Datalog query throughout this work
as an ongoing example because of its interesting properties:
It is a simple yet expressive example that encompasses recursion and negation,
two features that I deem as important for expressing \acp{CRDT}.

\ref{code:mvr-crdt-sql} shows an equivalent SQL query.
Although I structure the query with the same subqueries as in the Datalog
example, the SQL query is more verbose and arguably less readable.
I think that Datalog is more elegant, offers better support for composition,
and excels at expressing recursion~\cite{abo2024convergence},
which is important for more complex CRDTs~\cite{kleppmann2018data}.
Especially, I want to avoid the cumbersome syntax around recursive
common table expressions which remains unpopular even within the SQL
community~\cite{neumann2024critique, hirn2023fix, mcsherry2022recursion}.
Semantic-wise, recursion in SQL and Datalog are equivalent and
both require monotonically growing sets for recursive queries~\cite{hirn2023fix}.
Hence, there is no fundamental difference in terms of their semantics and
expressiveness but I see a notable difference in their syntax choices.
Therefore, I prefer Datalog's syntax which allows for declarative, compact
and composable queries. Ergonomic composability is key to enabling reusability.
Furthermore, there exists some recent research about defining Datalog
over arbitrary semirings~\cite{abo2024convergence, khamis2022datalog},
which may open up new avenues for Datalog's semantics and expressiveness
in the future.

\begin{figure}[tpb]
	\begin{subfigure}[b]{\textwidth}
		% \begin{tabular}{c}
		\begin{lstlisting}[keepspaces]
// EDBPs are omitted in this chapter.
overwritten(RepId, Ctr)     :- pred(RepId, Ctr, _, _).
overwrites(RepId, Ctr)      :- pred(_, _, RepId, Ctr).
isRoot(RepId, Ctr)          :- set(RepId, Ctr, Key, Value),
                               not overwrites(RepId, Ctr).
isLeaf(RepId, Ctr)          :- set(RepId, Ctr, Key, Value),
                               not overwritten(RepId, Ctr).
isCausallyReady(RepId, Ctr) :- isRoot(RepId, Ctr).
isCausallyReady(RepId, Ctr) :- isCausallyReady(FromRepId, FromCtr),
                               pred(FromRepId, FromCtr, RepId, Ctr).
mvrStore(Key, Value)        :- set(RepId, Ctr, Key, Value),
                               isCausallyReady(RepId, Ctr),
                               isLeaf(RepId, Ctr).\end{lstlisting}
		% \end{tabular}
		\caption{The \ac{MVR} key-value store with causal broadcast in Datalog.}\label{code:mvr-crdt-datalog}
	\end{subfigure}

	\vspace{1em}

	\begin{subfigure}[b]{\textwidth}
		% \begin{tabular}{c}
		\begin{lstlisting}[language=SQL]
WITH overwritten AS (SELECT FromRepId, FromCtr FROM pred)
WITH overwrites  AS (SELECT ToRepId, ToCtr FROM pred)
WITH isRoot      AS (SELECT RepId, Ctr FROM set
                    WHERE (RepId, Ctr) NOT IN overwrites)
WITH isLeaf      AS (SELECT RepId, Ctr FROM set
                    WHERE (RepId, Ctr) NOT IN overwritten)
WITH RECURSIVE isCausallyReady AS (
    SELECT * FROM isRoot
    UNION [ALL]
    SELECT pred.ToRepId, pred.ToCtr
    FROM pred, isCausallyReady
    WHERE pred.FromRepId = isCausallyReady.RepId
    AND pred.FromCtr = isCausallyReady.Ctr
)

SELECT set.key, set.value
FROM set, isCausallyReady, isLeaf
WHERE set.RepId = isCausallyReady.RepId
AND set.Ctr = isCausallyReady.Ctr
AND isCausallyReady.RepId = isLeaf.RepId
AND isCausallyReady.Ctr = isLeaf.Ctr\end{lstlisting}
		% \end{tabular}
		\caption{The \ac{MVR} key-value store with causal broadcast in SQL.}\label{code:mvr-crdt-sql}
	\end{subfigure}
\end{figure}

The example also demonstrates why atomic writes to the database are important.
Write \(w_2\) updates both the \code{set} and \code{pred} relations.
If the query reads state in which only the \code{set} relation,
but not the \code{pred} relation, has been updated,
the query incorrectly deems \setop{4}{r_1}{k_1}{y_3} as a new root and
again returns the invalid result from above.

While the issue of this section can be ignored by assuming a causal broadcast
either on the application or on the database layer,
I think that queries benefit from having the full causal history available.
It provides them with the ability to detect when operations are concurrent,
and use that information to adjust their conflict handling to perform
custom resolution logic.

\section{Why \emph{\acp{CRDT}} as Queries?}

Next to the higher-level abstraction provided by a query language like Datalog,
there is another important property that applies to \acp{CRDT} in particular.
\acp{CRDT} must satisfy strong eventual consistency~\cite{shapiro2011comprehensive}
to guarantee convergence in a coodination-free environment.
Proving the correctness of a \ac{CRDT} is a non-trivial
task~\cite{gomes2017verifying, kleppmann2022assessing},
and requires expertise in eventual consistency as well as proving strategies.
This is a prohibitively high entry barrier for application developers
wanting to use \acp{CRDT} in their applications.
With the model of expressing \acp{CRDT} as \emph{deterministic} queries over a
set of gossiped operations among replicas, the convergence property is trivially
satisfied, as I lay out in more detail in \autoref{ch:background}.
I hope that with this approach, the doors to using \acp{CRDT} in applications
are opened wider, as the application developer does not have to worry about
the critical convergence property anymore but is empowered to design her own
\ac{CRDT}, tailored to her application's needs.
Alas,this is not possible with today's \ac{CRDT} libraries.
They provide a fixed set of \ac{CRDT} types with a fixed set of operations
and conflict resolution strategies.
From the outside, they are mostly treated as black boxes.

Similar to how queries made data retrieval and storage more accessible to
application developers, I hope that expressing \acp{CRDT} as queries
makes collaborative software more accessible, too.
Another benefit is that application developers are already used to the concept
of a query, as nearly every application relies on a database in some form.
Furthermore, \ac{CRDT} queries and non-\ac{CRDT} queries can then share the
same interface~\cite{litt2023riffle}, reducing the cognitive load and the
complexity of the application stack.

\section{Query Execution}

The declarative nature of a query language leaves the execution to a query engine.
From the perspective of the application developer this is another advantage:
The exact implementation comes for free and many query engines are heavily
parallelized and optimized for performance. While the latter may be true
for some \ac{CRDT} libraries, they are often not taking advantage of the many
cores of today's computers.
Additionally, the abstraction level of a query language is quite high,
which has the advantage that the query engine can be optimized over time without
introducing breaking changes to the application.

Yet, operation-based \acp{CRDT}, which derive their state from a monotonically
growing set of operations, pose an additional challenge to query engines.
For each evaluation of the current state of the data structure,
traditional query engines have to re-evaluate the \emph{entire}
set of operations to derive the current state, performing the same work over
and over again.
With tight time budgets in the context of user interfaces, this can lead to
poor user experiences after exceeding a certain threshold of operations.
To address this issue, I focus on exploring \ac{IVM} for this work.

The promise of \ac{IVM} is that it can incrementally maintain a view defined
by a query, while only doing work relative to the size of the query's
inputs' \emph{change since the last evaluation}, as opposed to doing work
relative to the size of the query's \emph{full inputs},
as happening with traditional query engines.
To exacerbate the situation, the inputs are monotonically growing sets in this
case.
The issue is the stateless nature of non-incremental query engines, or rather
that they ``forget'' any previous work done for evaluations of the query,
and start from scratch every time.
This behavior is not a good fit with most \ac{CRDT} workloads.
They are often used in a near-real-time collaboration settings, in which there
are frequent updates both from the local and remote replicas, and the accrued
update sizes since the last evaluation are often minor compared to the total
size of the operation set due to the near-real-time nature of the collaboration.
Only after extended periods of offline time, the update sizes may grow larger.
Therefore, I regard \ac{IVM} as a key technique to make \acp{CRDT} as queries
feasible in practice:
If the query engine is only doing work relative to the amount of operations
accrued since the last evaluation, instead of relative to the full set of
operations, the query can be evaluated within acceptable time budgets,
irrespective of the size (and correlatedly age) of the operation history.
