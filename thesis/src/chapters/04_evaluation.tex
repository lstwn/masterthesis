% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Evaluation}\label{ch:evaluation}

This chapter assesses the suitability of my Datalog dialect from
\ref{sec:datalog-frontend} to express \acp{CRDT}-as-queries
in \ref{sec:crdts-as-queries}, by implementing two classes of \acp{CRDT} in it.
To evaluate the approach's viability in practice,
\ref{sec:benchmarks} presents benchmarks of the implemented \acp{CRDT}
which are executed on my query engine from \ref{ch:implementation}.

\section{\acsp{CRDT} as Queries}\label{sec:crdts-as-queries}

\ref{sec:key-value-stores-datalog-dialect} shows the familiar \ac{MVR} key-value
stores from \ref{ch:intro} in my Datalog dialect.
\ref{sec:list-crdt-datalog-dialect} implements a list \ac{CRDT} in my Datalog
dialect, which is adapted from~\cite{kleppmann2018data}.

\subsection{Key-Value Stores}\label{sec:key-value-stores-datalog-dialect}

\ref{code:mvr-store-datalog-dialect} shows the \ac{MVR} key-value store
from \ref{code:mvr-store-datalog} (which assumes causal broadcast)
in my Datalog dialect.
Examples in this chapter explicitly state the \acp{EDBP} to communicate the
predicates' schema to the query engine.

\begin{figure}[htpb]
    \begin{lstlisting}[keepspaces]
// EDBPs:
pred(FromRepId, FromCtr, ToRepId, ToCtr) :- .
set(RepId, Ctr, Key, Value)              :- .

// IDBPs:
distinct overwritten(RepId, Ctr)
                    :- pred(RepId = FromRepId, Ctr = FromCtr).
mvrStore(Key, Value)
                    :- set(RepId, Ctr, Key, Value),
                       not overwritten(RepId, Ctr).\end{lstlisting}
    \caption{
        The \ac{MVR} key-value store without causal broadcast in my Datalog
        dialect.
    }\label{code:mvr-store-datalog-dialect}
\end{figure}

\ref{code:mvr-crdt-datalog-dialect} provides a definition of the \ac{MVR}
key-value store \ac{CRDT} from \ref{code:mvr-crdt-datalog} in my Datalog dialect.
The query differentiates itself from the previous example by including the
causal broadcast mechanism.

\begin{figure}[htpb]
    \begin{lstlisting}[keepspaces]
// EDBPs are omitted because they are shared with the previous example. IDBPs:
distinct overwritten(RepId, Ctr)
                    :- pred(RepId = FromRepId, Ctr = FromCtr).
distinct overwrites(RepId, Ctr)
                    :- pred(RepId = ToRepId, Ctr = ToCtr).
isRoot(RepId, Ctr)  :- set(RepId, Ctr, _Key, _Value),
                       not overwrites(RepId, Ctr).
isLeaf(RepId, Ctr)  :- set(RepId, Ctr, _Key, _Value),
                       not overwritten(RepId, Ctr).
isCausallyReady(RepId, Ctr)
                    :- isRoot(RepId, Ctr).
isCausallyReady(RepId, Ctr)
                    :- isCausallyReady(FromRepId = RepId, FromCtr = Ctr),
                       pred(FromRepId, FromCtr, RepId = ToRepId, Ctr = ToCtr).
mvrStore(Key, Value)
                    :- isLeaf(RepId, Ctr),
                       isCausallyReady(RepId, Ctr),
                       set(RepId, Ctr, Key, Value).\end{lstlisting}
    \caption{
        The \ac{MVR} key-value store including causal broadcast in my Datalog
        dialect.
    }\label{code:mvr-crdt-datalog-dialect}
\end{figure}

Both examples are similar to their counterparts from \ref{ch:intro}
expressed in ``conventional'' Datalog.
Key differences are the inclusion of \acp{EDBP}, the use of name-based indexing,
and the explicit use of the ``distinct'' operator to ensure that a predicate
has set (instead of multiset) semantics.

\subsection{List \acs{CRDT}}\label{sec:list-crdt-datalog-dialect}

List \acp{CRDT} enable replicas to converge to the same sequence of elements.
Fundamentally, they support two kinds of operations:
The insertion and the deletion of an element at a position.
They are often discussed in the context of collaborative text
editing in which the list maintains the sequence of characters as they appear
in the shared text.
Yet, most list \acp{CRDT} can go beyond this application and store arbitrary
elements.
Among others, Treedoc~\cite{treedoc}, Logoot~\cite{logoot}, \ac{RGA}~\cite{rga},
and Fugue~\cite{fugue} have been proposed.
Causal trees~\cite{causal-trees} and timestamped insertion
trees~\cite{timestamped-insertion-trees} are tree-based reformulations
of \ac{RGA}.

List \acp{CRDT} are more complex than key-value stores because they have to
converge to the \emph{same order} of elements across replicas under concurrent
updates.
The list \ac{CRDT} presented here resembles the causal tree \ac{RGA} formulation,
which is based on the idea that insertions do not specify an index for their
position, but instead each list element is assigned a unique, immutable identifier,
and each insertion references the identifier of the element after which it wants
to be inserted.
This implies that deletions cannot fully remove an element, but have to leave
\emph{tombstones} behind, to avoid dangling references in case of an
insertion after element \(x\) and a concurrent deletion of \(x\).
In case of concurrent insertions after the same element \(x\),
the inserted elements are ordered according to the total order induced
by the identifiers.
The identifiers can again be replica id and counter pairs,
and they provide a total order by first comparing the counters and,
in case of ties, by breaking them through comparing the replica ids.
I initially focus only on insertions into the list, and discuss deletions later.

Logically, each insertion of an element into the list can be represented in a
tree structure, where each node's \emph{parent} is the element after which it
is supposed to be inserted (but may not in the final list order due to
concurrent insertions).
The root element is some sentinel element that is always present and does not
contribute to the list's content.
A node's \emph{children} are \emph{descendingly} ordered by their identifiers.
The number of children corresponds to the number of concurrent insertions
after the parent element, i.e., siblings are a result of concurrency.
The final list order is given by a depth-first, pre-order traversal of the tree.
At its core, the Datalog query has to implement this depth-first, pre-order
traversal of the tree.

\begin{figure}[htpb]
    \centering

    \begin{subfigure}[b]{\textwidth}
        \begin{lstlisting}[keepspaces,escapechar=!]
// Black edges in !\ref{fig:list-crdt}!.
insert(RepId, Ctr, ParentRepId, ParentCtr, Value) :- .
remove(ElemId, ElemCtr) :- .

laterChild(ParentRepId, ParentCtr, ChildRepId, ChildCtr) :-
    insert(SiblingRepId = RepId, SiblingCtr = Ctr, ParentRepId, ParentCtr),
    insert(ChildRepId = RepId, ChildCtr = Ctr, ParentRepId, ParentCtr),
    (SiblingCtr > ChildCtr; (SiblingCtr == ChildCtr, SiblingRepId > ChildRepId)).

// Dotted, green edges in !\ref{fig:list-crdt}!.
firstChild(ParentRepId, ParentCtr, ChildRepId, ChildCtr) :-
    insert(ChildRepId = RepId, ChildCtr = Ctr, ParentRepId, ParentCtr),
    not laterChild(ParentRepId, ParentCtr, ChildRepId, ChildCtr).\end{lstlisting}
        \caption{Part 1: Definition of ``insert'' \ac{EDBP} and ``firstChild'' \ac{IDBP}.}\label{code:list-crdt-datalog-dialect-part1}
    \end{subfigure}

    \vspace{1em}

    \begin{subfigure}[b]{\textwidth}
        \begin{lstlisting}[keepspaces,escapechar=!]
sibling(Child1RepId, Child1Ctr, Child2RepId, Child2Ctr) :-
    insert(Child1RepId = RepId, Child1Ctr = Ctr, ParentRepId, ParentCtr),
    insert(Child2RepId = RepId, Child2Ctr = Ctr, ParentRepId, ParentCtr).

laterSibling(Child1RepId, Child1Ctr, Child2RepId, Child2Ctr) :-
    sibling(Child1RepId, Child1Ctr, Child2RepId, Child2Ctr),
    (Child1Ctr > Child2Ctr; (Child1Ctr == Child2Ctr, Child1RepId > Child2RepId)).

laterIndirectSibling(Child1RepId, Child1Ctr, Child3RepId, Child3Ctr) :-
    sibling(Child1RepId, Child1Ctr, Child2RepId, Child2Ctr),
    sibling(Child1RepId, Child1Ctr,
        Child3RepId = Child2RepId, Child3Ctr = Child2Ctr),
    (Child1Ctr > Child2Ctr; (Child1Ctr == Child2Ctr, Child1RepId > Child2RepId)),
    (Child2Ctr > Child3Ctr; (Child2Ctr == Child3Ctr, Child2RepId > Child3RepId)).

// Dashed, orange edges in !\ref{fig:list-crdt}!.
nextSibling(Child1RepId, Child1Ctr, Child2RepId, Child2Ctr) :-
    laterSibling(Child1RepId, Child1Ctr, Child2RepId, Child2Ctr),
    not laterIndirectSibling(Child1RepId, Child1Ctr,
        Child2RepId = Child3RepId, Child2Ctr = Child3Ctr).\end{lstlisting}
        \caption{Part 2: Definition of ``nextSibling'' \ac{IDBP}.}\label{code:list-crdt-datalog-dialect-part2}
    \end{subfigure}
\end{figure}

\begin{figure}[htpb]\ContinuedFloat
    \centering

    \begin{subfigure}[b]{\textwidth}
        \begin{lstlisting}[keepspaces,escapechar=!]
distinct hasNextSibling(ChildRepId, ChildCtr) :-
    nextSibling(ChildRepId = Child1RepId, ChildCtr = Child1Ctr).

// Dashdotted, blue edges in !\ref{fig:list-crdt}!.
nextSiblingAnc(ChildRepId, ChildCtr, AncRepId, AncCtr) :-
    nextSibling(ChildRepId = Child1RepId, ChildCtr = Child1Ctr,
        AncRepId = Child2RepId, AncCtr = Child2Ctr).
nextSiblingAnc(ChildRepId, ChildCtr, AncRepId, AncCtr) :-
    insert(ChildRepId = RepId, ChildCtr = Ctr, ParentRepId, ParentCtr),
    not hasNextSibling(ChildRepId, ChildCtr),
    nextSiblingAnc(ParentRepId = ChildRepId, ParentCtr = ChildCtr,
        AncRepId, AncCtr).

distinct hasChild(ParentRepId, ParentCtr) :-
    insert(ParentRepId, ParentCtr).

nextElem(PrevRepId, PrevCtr, NextRepId, NextCtr) :-
    firstChild(PrevRepId = ParentRepId, PrevCtr = ParentCtr,
        NextRepId = ChildRepId, NextCtr = ChildCtr).
nextElem(PrevRepId, PrevCtr, NextRepId, NextCtr) :-
    not hasChild(PrevRepId = ParentRepId, PrevCtr = ParentCtr),
    nextSiblingAnc(PrevRepId = ChildRepId, PrevCtr = ChildCtr,
        NextRepId = AncRepId, NextCtr = AncCtr).\end{lstlisting}
        \caption{Part 3: Definition of ``nextSiblingAnc'' and ``nextElem'' \acp{IDBP}.}\label{code:list-crdt-datalog-dialect-part3}
    \end{subfigure}
\end{figure}

\begin{figure}[htpb]\ContinuedFloat
    \centering

    \begin{subfigure}[b]{\textwidth}
        \begin{lstlisting}[keepspaces,escapechar=!]
distinct hasValue(ElemId, ElemCtr) :-
    // Fix for not being able to assign anything to the sentinel element.
    insert(ElemId = ParentRepId, ElemCtr = ParentCtr),
    ElemId == 0, ElemCtr == 0.
distinct hasValue(ElemId, ElemCtr) :-
    insert(ElemId = RepId, ElemCtr = Ctr),
    not remove(ElemId, ElemCtr).

nextElemSkipTombstones(PrevRepId, PrevCtr, NextRepId, NextCtr) :-
    nextElem(PrevRepId, PrevCtr, NextRepId, NextCtr).
nextElemSkipTombstones(PrevRepId, PrevCtr, NextRepId, NextCtr) :-
    nextElem(PrevRepId, PrevCtr, ViaRepId = NextRepId, ViaCtr = NextCtr),
    not hasValue(ViaRepId = ElemId, ViaCtr = ElemCtr),
    nextElemSkipTombstones(ViaRepId = PrevRepId, ViaCtr = PrevCtr,
        NextRepId, NextCtr).

nextVisible(PrevRepId, PrevCtr, NextRepId, NextCtr) :-
    hasValue(PrevRepId = ElemId, PrevCtr = ElemCtr),
    nextElemSkipTombstones(PrevRepId, PrevCtr, NextRepId, NextCtr),
    hasValue(NextRepId = ElemId, NextCtr = ElemCtr).

listElem(PrevRepId, PrevCtr, Value, NextRepId, NextCtr) :-
    nextVisible(PrevRepId, PrevCtr, NextRepId, NextCtr),
    insert(NextRepId = RepId, NextCtr = Ctr, Value).\end{lstlisting}
        \caption{Part 4: Definition of ``listElem'' \ac{IDBP}.}\label{code:list-crdt-datalog-dialect-part4}
    \end{subfigure}
    \caption{A list \ac{CRDT} in my Datalog dialect, adapted from~\cite{kleppmann2018data}.}\label{code:list-crdt-datalog-dialect}
\end{figure}

\input{figures/list_crdt.tex}

\ref{code:list-crdt-datalog-dialect} shows the definition of a list \ac{CRDT}
in my Datalog dialect.
To explain the query, I use \ref{fig:list-crdt} as an example in which
three replicas, with id 1, 2, and 3, insert elements into the list.
\ref{fig:list-crdt} visualizes the
``insert(RepId, Ctr, ParentRepId, ParentCtr, Value)'' \ac{EDBP} with entries:

\[\{ (2,1,0,0,'H'), (2,3,2,1,'E'), (1,3,2,1,'L'), (3,2,2,1,'L'), (1,1,0,0,'O'), (2,2,1,1,'!') \}\]

Every node (except for the sentinel root) depicts a (\textit{RepId}, \textit{Ctr})
pair and its black edge points to its parent defined by
a (\textit{ParentRepId}, \textit{ParentCtr}) pair.
The edge's label shows the value of the inserted element.
The result of the depth-first, pre-order traversal is:

\[[ (0,0), (2,1), (2,3), (1,3), (3,2), (1,1), (2,2) ]\]

Despite the absence of a built-in list type in Datalog, I reproduce this result
as an (unsorted) linked list of nodes in \ref{code:list-crdt-datalog-dialect}
with the help of the ``nextElem'' \ac{IDBP}.
Its definition is divided into three parts.
First, the ``firstChild'' \ac{IDBP} (\ref{code:list-crdt-datalog-dialect-part1})
finds the first child of each parent
(the dotted, green edges in \ref{fig:list-crdt}).
To do so, it relies on the ``laterChild'' \ac{IDBP} to find all parents with
their children such that the children are not their first but a later child.
Second, the ``nextSibling'' \ac{IDBP} (\ref{code:list-crdt-datalog-dialect-part2})
provides the next sibling of each child
(the dashed, orange edges in \ref{fig:list-crdt}).
Its definition makes use of the ``laterSibling'' and ``laterIndirectSibling''
\acp{IDBP}. The former finds all later siblings of a child, and the latter
finds all later siblings of a child that are not direct siblings but have
at least one sibling in between them.
Then, the next sibling of a child is given by filtering out all later
\emph{indirect} siblings from the later siblings.
Third, the ``nextSiblingAnc'' \ac{IDBP} (\ref{code:list-crdt-datalog-dialect-part3})
gives the next sibling of each child, or, recursively,
the next sibling of the parent if a child has no next sibling
(the dashdotted, blue edges in \ref{fig:list-crdt}).
Finally, the ``nextElem'' \ac{IDBP} defines the depth-first, pre-order traversal
by either yielding a link from the parent to its first child (as ``previous''
and ``next'', respectively) or a link defined by the ``nextSiblingAnc'' \ac{IDBP}
if the ``previous'' node has no child.
This outputs the above result as a linked list of nodes where each node is
defined by a (\textit{RepId}, \textit{Ctr}) pair:

\[\{ (0,0,2,1), (2,1,2,3), (2,3,1,3), (1,3,3,2), (3,2,1,1), (1,1,2,2) \}\]

Every deletion generates an entry in the ``remove'' \ac{EDBP} with the
(\textit{RepId}, \textit{Ctr}) pair of the node to be deleted.
Therefore, some nodes may not have a value assigned anymore, in which case
they represent a tombstone and must be skipped in the output.
To achieve that, the ``listElem'' \ac{IDBP}
(\ref{code:list-crdt-datalog-dialect-part4}) is used, which relies on
the ``nextElemSkipTombstones'' and ``nextVisible'' \acp{IDBP}.
The former is based on the ``nextElem'' \ac{IDBP} but additionally contains
longer paths derived from the ``nextElem`` predicate which skip tombstoned nodes.
The ``hasValue'' \ac{IDBP} checks whether a node has been tombstoned or not,
and the first rule of its definition ensures that the sentinel root element
(with id \((0, 0)\)) is always considered to have a value assigned to it.
This is required to prevent the ``nextVisible'' \ac{IDBP} from skipping the
first list element.
The ``nextVisible'' \ac{IDBP} ensures that each node from the node pairs
reported by the  ``nextElemSkipTombstones'' \ac{IDBP} has a value assigned to it.
Finally, the ``nextElem'' \ac{IDBP} joins the non-tombstoned list elements'
values to the pairs of nodes from the ``nextVisible'' \ac{IDBP}.
The final list result for the example from \ref{fig:list-crdt} is:

\[\{ (0,0,'H',2,1), (2,1,'E',2,3), (2,3,'L',1,3), (1,3,'L',3,2), (3,2,'O',1,1), (1,1,'!',2,2) \}\]

The output may not be sorted as shown above.
The list can be obtained by walking the linked list starting from
the sentinel root element with id \((0, 0)\) and collecting the values along
the way which yields the text ``HELLO!''.

To demonstrate the nature of incremental computations and the deletion of elements,
I continue the example with two successive deletions of elements and show
the output \emph{changes} after each deletion.
Output changes are encoded as tagged tuples as described in \ref{sec:ivm}.
The two deletions are applied on top of the state of the list and its inputs from
\ref{fig:list-crdt}.
In the first step, the last element ``!'' is deleted, which adds the fact
``remove(2,2)'' to the ``remove'' \ac{EDBP}. This yields the output change:

\[\{ (-1, (1,1,'!',2,2)) \}\]

The first entry of the tagged tuple is the \zweight{} of \(-1\) and indicates
a deletion of the tuple \((1, 1, '!', 2, 2)\) (second entry of the pair)
from the previous list state.
This yields the text ``HELLO''.

The second step deletes the first element ``H'' and causes the fact
``remove(2,1)'' to be inserted into the ``remove'' \ac{EDBP}.
A reevaluation then emits the following output changes:

\[\{
(-1, (0, 0, 'H', 2, 1)),
(-1, (2, 1, 'E', 2, 3)),
( 1, (0, 0, 'E', 2, 3))
\}\]

The first two changes retract two tuples from the previous output state and the
third change adds a new tuple because of its \zweight{} of \(1\).
Due to the nature of linked lists, any deletion of an element, which is \emph{not}
the last element, triggers three output changes: One for the deletion of the element
itself and two for replacing the previous ``pointer'' of the deleted element's
successor in the list.
The final text is now ``ELLO''.

\section{Performance Evaluation}\label{sec:benchmarks}

\ref{sec:bench-hydration} and \ref{sec:bench-nrt}
provide benchmarks of the three \acp{CRDT} from the previous section.
Benchmarking happens in two different settings which are distinguished by
the operators of the query plan being either ``cold'' or ``warm'':

\begin{itemize}
    \item \textbf{Hydration setting} (\ref{sec:bench-hydration}).
          As outlined in \ref{sec:ivm}, all bilinear operators are stateful.
          Hence, all stateful operators of the query plan have to restore
          their state before processing any new updates, e.g., in case of a
          ``cold'' application restart. This benchmark measures the time it takes
          until the application can show its last state and process \emph{new}
          updates again on top of an existing operation history.
    \item \textbf{Near-real-time setting} (\ref{sec:bench-nrt}).
          In this setting, the operators are assumed to be ``warm'' and only
          a small number of updates are new to them.
          This benchmark measures the common operation mode of \acp{CRDT} after
          the application has started up. It measures how much time it takes
          to process a small number of updates on top of an already ``hydrated''
          query plan.
\end{itemize}

All benchmarks are executed on a 2024 MacBook Pro with an Apple M4 Pro CPU.
DBSP's runtime is configured to run in a single thread due to correctness
issues with its multi-threaded execution for queries that use recursion.
Although I am not sure about the exact reason,
I suspect that this is because some of DBSP's operators are not thread-safe,
as mentioned in their
\href{https://docs.rs/dbsp/0.64.0/dbsp/circuit/struct.Runtime.html\#method.init_circuit}{documentation}.
Unfortunately, it currently lacks a list of non-thread-safe operators
and does not explain the issue any further\footnotemark{}.

\footnotetext{
    \url{https://docs.rs/dbsp/0.64.0/dbsp/circuit/struct.Runtime.html\#method.init_circuit}
}

\subsection{Hydration Setting}\label{sec:bench-hydration}

As the hydration setting's purpose is to model application startups,
it includes the time it takes to parse the \ac{CRDT} Datalog query and
set up the query plan, in addition to feeding in an existing causal history.
In other words, it also measures the time spent during query build-time.

The benchmark for the key-value stores in the hydration setting is set up as follows.
The \emph{base diameter} \(\in \{1000, 2000, 3000, 4000, 5000\}\) is the diameter
of the causal history if viewed as a directed graph,
i.e., it is the longest shortest path from a root to a leaf.
Because the causal history is a chain of operations with no concurrency,
the base diameter is equal to the number of operations (plus one).
All operations are generated at one replica and write to the same key.
The recorded operations during that process are then fed into the DBSP circuit
after it has been constructed.

\input{figures/bench_kv_store_hdr.tex}

\ref{fig:hydration-kv-store} shows the results of both the key-value store
without causal broadcast from \ref{code:mvr-store-datalog-dialect} and the
key-value store including causal broadcast from \ref{code:mvr-crdt-datalog-dialect}.
The causal broadcast mechanism has a significant impact on the performance:
While an increase of the base diameter by 1000 causes the performance of the
key-value store without causal broadcast to increase by roughly two milliseconds,
the key-value store's performance including causal broadcast increases by about
40 milliseconds.
The reason for this behavior the graph traversal of the causal history from its
roots to its leaves to find the causally ready operations.
The fixed point iteration responsible for this graph traversal requires evaluating
a sequence of \emph{dependent} joins relative to the size of the diameter
of the causal history.

\input{figures/bench_list_hdr.tex}

\ref{fig:bench-list-hdr} shows the benchmark results of the list \ac{CRDT}.
The benchmark generates a causal history of successive insert operations, i.e.,
there are no deletions and cursor jumps but only consecutive insertions that
gradually build up the text by inserting new characters at the end of the list.
Hence, the \emph{base text length} \(\in \{10000, 20000, 30000, 40000, 50000\}\)
is the number of insert operations.
The benchmark shows that an increase in the base text length by 10000 insertions
causes an increase in the runtime of about 200 milliseconds.
Loading a document with 50000 operations in this scenario takes about a second.

\subsection{Near-Real-Time Setting}\label{sec:bench-nrt}

The near-real-time setting extends the hydration setting insofar that it builds
upon the states of the hydration setting.
After the operators have been hydrated according to the parameters of the
hydration setting, this benchmark feeds in only a small number of additional updates.
The new batch of updates is inserted at once and then processed by the DBSP circuit.
The benchmark does not account for the time it takes to parse the Datalog query
nor to set up the DBSP circuit, as the near-real-time setting simulates
the situation in which the application has already started up and is running.

\input{figures/bench_kv_store_nrt.tex}

\ref{fig:bench-kv-stores-nrt} shows benchmark results of the key-value stores.
A \emph{delta diameter} of size \(d \in \{20, 40, 60, 80, 100\}\) extends the
chain of operations from the hydration setting by \(d\) additional operations.
The benchmark reveals some interesting patterns.
For the key-value store without causal broadcast
from \ref{code:mvr-store-datalog-dialect},
the base diameter has no impact on the performance.
Varying the delta diameter has only a small impact on the
performance (\ref{fig:bench-kv-store-nrt-nocb}).
In any case, processing the updates takes less than a quarter of a millisecond.
The key-value store including causal broadcast
from \ref{code:mvr-crdt-datalog-dialect} shows only a small impact from
varying the delta diameter, too.
The base diameter, on the other hand, has a significant impact on the performance
(\ref{fig:bench-kv-store-nrt-cb}):
An increase in the base diameter by 1000 causes an increase of the runtime of
about 20 milliseconds, rendering this \ac{CRDT} \emph{dependent} on the age
of the causal history.
This is again due to the dependent joins of the causal broadcast's fixed point
iteration.
I suspect that even a multi-threaded execution would not improve the performance
in this case, as the joins are dependent, rendering the computation inherently
sequential.
However, a clever query optimizer could possibly turn the causal broadcast into
a near constant time operation by, e.g., testing causal readiness of a new operation
from the current leaves of the causal history and thus avoiding the
costly search from the roots, as most new operations are likely a causal successor
of the current leaves.

\input{figures/bench_list_nrt.tex}

\ref{fig:bench-list-nrt} shows the benchmark results of the list \ac{CRDT}.
A \emph{delta text length} of size \(d \in \{20, 40, 60, 80, 100\}\) adds
a burst of \(d\) successive insertions at the end of the list, respectively.
Applying the burst and evaluating the list \ac{CRDT} takes between 1.5 and
5.25 milliseconds depending on the base text length and the delta text length.
Similar to the key-value store including causal broadcast,
the base text length has an impact on the performance, albeit not as significant.
A base text length increase of 10000 causes an increase in the runtime by roughly
half a millisecond.
Increasing the delta text length by 20 causes an increase in the runtime
by about 0.4 milliseconds for all base text lengths.

\section{Related Work}\label{sec:related-work}

The idea of using restricted languages to express \acp{CRDT} to guarantee
their convergence has been explored in the past.
VeriFx~\cite{verifx}, Propel~\cite{propel}, and LoRe~\cite{lore} introduce
custom \acp{DSL} to define \acp{CRDT}.
From \ac{CRDT} definitions in the \ac{DSL}, they derive both an implementation
of the \ac{CRDT} and its proof of convergence.
The verification is handed off to a \acs{SAT} solver, which is used to
prove that the \ac{CRDT} converges under concurrent updates.
LoRe differs from VeriFx insofar that it can also express invariants that
require coordination between replicas and inject such coordination logic
automatically, freeing the application developer from writing synchronization
code.
Unlike \acp{DSL}, Datalog has the advantage that is a more widely used language
and does not require verification time because convergence is guaranteed by
construction.

There exist several libraries that implement \acp{CRDT} in general-purpose
programming languages, for instance, Automerge~\cite{automerge} (Rust),
Yjs~\cite{yjs} (JavaScript), Collabs~\cite{collabs} (TypeScript),
and Loro~\cite{loro} (Rust).
They come with no formal proof of convergence but are crafted by experienced
developers familiar with eventual consistency and are widely used in practice.
Yet, changing them to support custom data types is a challenging task and
requires a deep understanding of the library's internals as well as theoretical
foundations of \acp{CRDT}, rendering them less flexible than language based
approaches.

Other \ac{CRDT} frameworks are based on (immutable) event logs, deriving state
from the log, and replaying events in a consistent order across replicas to
handle concurrent updates and/or updates which are delivered out-of-order.
The idea has been formalized in \cite{baquero2017pure} and is applied in
the Eg-walker~\cite{egwalker} algorithm in the context of collaborative text
editing.
LiveStore~\cite{livestore} is a recent framework, which allows developers
to specify events and how to derive state from them.
If the derivation happens deterministically, convergence is guaranteed, too,
due to the consistent event order across replicas.
Yet, the event order is unstable in case of concurrent or out-of-order events,
as they require undoing and (re)applying events.
This renders supporting list operations challenging because the list operations'
indexes may need to be transformed to match the different list order based on
the new event order.

In general, there are two predominant approaches to query execution,
\emph{interpreted} and \emph{compiled} query execution.
The former executes a query by interpreting its query plan at run-time,
usually on the granularity level of an operator of the query plan.
Compiled query execution has been pioneered by the HyPer main memory database
system~\cite{neumann2011efficiently}.
It compiles a query plan into an executable tailored to the specific query,
can therefore take advantage of, e.g., combining multiple non-blocking operators
into a single loop, and avoids interpretation overhead.
While compiled query execution sounds more promising in terms of performance,
it is more complex to implement, debug, and, surprisingly, its performance
is not necessarily better~\cite{kersten2018everything}.
Interestingly, DBSP's repository includes a SQL-to-DBSP compiler which emits
a Rust executable to execute a specific query~\cite{felderarepo}.
The now-unmaintained Differential Datalog project~\cite{ddlog, ddlogpaper},
which relies on differential dataflow~\cite{mcsherry2013differential},
also compiles a query plan into a Rust executable.
The strong preference for compiled query execution is unclear to me and,
as stated in \ref{sec:future-work}, I am interested in seeing their differences
being analyzed more closely, especially in the context of \emph{incremental}
query engines.
Only \cite{dynamicdatalog} explores executing Datalog queries incrementally
on top of DBSP through an interpreter but it only supports positive Datalog.
In comparison to my approach, it allows adding and removing rules dynamically
at run-time and it is more tied to DBSP because the evaluation happens
directly on a DBSP circuit without an \ac{IR} as an abstraction.

There are two predominant approaches for incremental computations beyond
the bag algebra approach:
Either they are based on differential dataflow~\cite{mcsherry2013differential}
and timely dataflow~\cite{timelydataflow}, or they are based on
the DBSP~\cite{budiu2024dbsp, budiu2025dbsp}.
Both approaches are backed by a commercial offering,
Feldera~\cite{felderainc} and Materialize~\cite{materializeinc}, respectively.
A prominent representative of non-incremental Datalog engines is
Soufflé~\cite{souffle} which compiles Datalog queries into C++ code to execute
them efficiently.
Ascent~\cite{ascent} allows seamlessly embedding Datalog queries into Rust
programs by defining them through Rust's macros.
Flix~\cite{flix} extends Datalog's semantics with support for lattices to
facilitate expressing programs to solve problems in static program analysis.
Datafrog~\cite{datafrog} is a Rust library that does not implement a Datalog
dialect but provides library functions to express Datalog-style rules and
execute them in the context of the calling thread.
