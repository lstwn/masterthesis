% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Conclusion}\label{ch:conclusion}

\section{Future Work}\label{sec:future-work}

In this work, I took several technical decisions to have a working prototype
available but many of them leave open questions for future work.
First, this work chooses DBSP as the \ac{IVM} framework for the query engine.
This leaves the question how other \ac{IVM} frameworks, such as differential
dataflow~\cite{mcsherry2013differential}, compare to DBSP in their performance
and expressiveness for this use case.
Second, it is an open question if (and by what margin) compiling query plans
outperforms interpreting them in the context of \ac{IVM}.
Third, what benefit could a mixed model of incremental and non-incremental
computations provide:
Possibly, it may be faster to prefer non-incremental execution during application
startup (the hydration setting) and then switch to incremental execution for
processing updates (the near-real time setting).
The required hydration of the operators for the incremental execution could be
moved to a background thread.
Alternatively, the operators' state could somehow be persisted to disk such that
the query engine can resume from a previous state and does not have to
feed in all updates again, in which case the query engine may not need
to support a non-incremental mode at all.

To minimize the interpretation overhead of the query engine, it could
benefit from some performance engineering.
Tuples are currently represented as vectors and, hence, each tuple access
may cause a cache miss.
Testing different physical data layouts for tuples, e.g., overflow-to-heap
vectors\footnotemark{}, could be an interesting direction to explore.
To further optimize away cache misses, the physical representation of an
\ac{IR} program could be adapted to use a more cache-friendly data layout, too:
Instead of expressions storing references to other expressions in their
input fields, they could be flattened by storing an index into a vector of
expressions, as laid out in~\cite{sampson2023flattening}.
This may improve spatial locality, thereby reducing cache misses, and is
particularly relevant for code that is run at query execution-time because
it is executed frequently (per tuple) instead of just once at query build-time
for creating the query plan.

\footnotetext{
	Overflow-to-heap vectors are vectors that store their elements
	in a contiguous memory region, but if the vector grows beyond a certain
	threshold, it allocates a new memory region on the heap and moves new
	elements there.
	Rust's \href{https://docs.rs/smallvec/latest/smallvec/}{\texttt{smallvec}}
	library implements this concept.
}

Applying serious query optimization has the potential to improve
the performance of the query engine but this is a challenge in its own right.
Particularly, in the context of \ac{IVM} and transpilation from Datalog to
relational algebra, I want to emphasize three aspects:

\begin{itemize}
	\item \textbf{Join ordering}.
	      As discussed in \ref{sec:ivm}, changing a query plan for a continuously
	      evaluated query can be costly.
	      Also, the query plan has to be chosen upfront and with the absence of
	      statistics about the data.
	      Hence, to what extent is an automated join ordering algorithm useful
	      in this context? Possibly, it may be better to let the query
	      author choose a definitive join order or allow them to provide
	      information about data distributions in case of automated join ordering.
	\item \textbf{Scheduling of antijoins}.
	      Negative atoms are handled with antijoins in the query engine.
	      So far, they are scheduled after the query plan covering the
	      positive atoms.
	      However, antijoins may actually be scheduled better by placing them
	      as early as possible, i.e., if all variables referenced by a
	      negative atom are in scope, to keep the intermediate result set small.
	      This is  because in the worst case, antijoins leave the intermediate
	      result set unchanged but in the average case they filter tuples out.
	      This is similar to predicate pushdown and, therefore, I call this
	      problem \emph{antijoin pushdown}.
	\item \textbf{Query optimization with Datalog}.
	      As this approach uses both Datalog and relational algebra,
		  there are two abstraction levels upon which query optimization
		  can be applied.
		  Although query optimization on Datalog has been studied
		  to a lesser extent, it may offer other, unexplored possibilities
		  which can only (or better) be applied on the Datalog level.
		  Also, this requires researching the interaction between
		  Datalog and relational algebra optimizations.
\end{itemize}

Feature-wise, the query engine could be extended to support mutual recursion
and aggregation but I do not consider these features essential for the
\ac{CRDT} use case. On the other hand, native JSON support may be useful for
defining a JSON \ac{CRDT} like Automerge does.
As motivated in \ref{sec:datalog-to-relational-algebra}, supporting multiple
main predicates of interest in a single query is not yet implemented but useful
in practice.
To improve practical usability of the Datalog frontend,
a type checking pass, better error reporting, and supporting tuples as a scalar
type could be added to the query engine.
The latter allows collapsing operations' replica id and counter fields
into a single field, to make Datalog \ac{CRDT} queries more concise.
To use this approach in practice, some more engineering effort is required.
The query engine is currently just a computation engine and does not provide
a durable storage layer for the underlying data.
Additionally, it remains unclear how compatible this approach is with
partial synchronization and update compaction, to keep storage sizes manageable
on smaller edge devices which cannot afford to store a monotonically growing
set of updates.

\ref{sec:crdts-as-queries} defines map and list \acp{CRDT} as queries.
More research is needed to define and benchmark further \acp{CRDT} as queries
before putting this idea into practice.
It is especially important to better understand their performance under various
workloads, e.g., different concurrency patterns, to guide future directions for
optimizing the query engine.
Finally, the question remains if there are \acp{CRDT} that cannot be expressed
with Datalog's restricted expressiveness with stratified negation.
A move operation in replicated trees~\cite{moveop1,moveop2} may be a challenging
candidate, as it requires rolling back updates to a previous state,
applying the move operation, then reapplying the previously undone updates,
and potentially aborting if a cycle is detected.

\section{Outlook}\label{sec:outlook}

Similar to how queries made data retrieval and storage more accessible to
application developers, I hope that expressing \acp{CRDT} as queries
makes \acp{CRDT} more accessible to a wider audience, too.
This approach has the potential to simplify the development of
collaborative, local-first applications~\cite{kleppmann2019local},
by allowing developers to focus on the application logic instead of the
underlying problems in eventually consistent, distributed systems, while
still providing the possibility to fine-tune a \ac{CRDT}'s behavior.

Furthermore, I hope that this work inspires others to seriously consider Datalog
as an alternative to SQL for a query language due to its succinct syntax
and solid foundation in logic programming.
